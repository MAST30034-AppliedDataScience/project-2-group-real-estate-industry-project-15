{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all merged feature sets\n",
    "\n",
    "one_bed_flat_merged = pd.read_csv('../data/curated/merged_feature_set/one_bed_flat_merged.csv')\n",
    "two_bed_flat_merged = pd.read_csv('../data/curated/merged_feature_set/two_bed_flat_merged.csv')\n",
    "three_bed_flat_merged = pd.read_csv('../data/curated/merged_feature_set/three_bed_flat_merged.csv')\n",
    "\n",
    "two_bed_house_merged = pd.read_csv('../data/curated/merged_feature_set/two_bed_house_merged.csv')\n",
    "three_bed_house_merged = pd.read_csv('../data/curated/merged_feature_set/three_bed_house_merged.csv')\n",
    "four_bed_house_merged = pd.read_csv('../data/curated/merged_feature_set/four_bed_house_merged.csv')\n",
    "\n",
    "all_properties_merged = pd.read_csv('../data/curated/merged_feature_set/all_properties_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_sets(df):\n",
    "    \"\"\"\n",
    "    This function splits the dataframe into training, validation, and testing sets\n",
    "    based on the 'year' column:\n",
    "    - Training set: 2016-2021\n",
    "    - Validation set: 2022-2024\n",
    "    - Testing set: 2025-2027\n",
    "\n",
    "    It retains the year and suburb columns for each dataframe. This is why we call \n",
    "    these dataframes '_labels'. \n",
    "\n",
    "    The function returns:\n",
    "    - X_train, X_val, X_test: Feature sets\n",
    "    - y_train, y_val, y_test: Target sets\n",
    "    \"\"\"\n",
    "    # Define the year ranges\n",
    "    train_years = range(2016, 2022)\n",
    "    val_years = range(2022, 2025)\n",
    "    test_years = range(2025, 2028)\n",
    "\n",
    "    # Define target columns (excluding suburb and year from the drop)\n",
    "    target_columns = ['dec_median', 'jun_median', 'mar_median', 'sep_median']\n",
    "\n",
    "    # Keep suburb and year in the features\n",
    "    X = df.drop(columns=target_columns)  # This keeps 'suburb' and 'year' in X\n",
    "    y = df[['suburb', 'year'] + target_columns]  # Target includes suburb, year, and target columns\n",
    "\n",
    "    # Split into train, validation, and test sets based on the year\n",
    "    X_train = X[X['year'].isin(train_years)]\n",
    "    X_val = X[X['year'].isin(val_years)]\n",
    "    X_test = X[X['year'].isin(test_years)]\n",
    "\n",
    "    y_train = y[y['year'].isin(train_years)]\n",
    "    y_val = y[y['year'].isin(val_years)]\n",
    "    y_test = y[y['year'].isin(test_years)]\n",
    "\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "# Create training, validation, and test sets for each property type\n",
    "X_train_one_bed_labels, X_val_one_bed_labels, X_test_one_bed_labels, y_train_one_bed_labels, y_val_one_bed_labels, y_test_one_bed_labels = train_val_test_sets(one_bed_flat_merged)\n",
    "X_train_two_bed_labels, X_val_two_bed_labels, X_test_two_bed_labels, y_train_two_bed_labels, y_val_two_bed_labels, y_test_two_bed_labels = train_val_test_sets(two_bed_flat_merged)\n",
    "X_train_three_bed_labels, X_val_three_bed_labels, X_test_three_bed_labels, y_train_three_bed_labels, y_val_three_bed_labels, y_test_three_bed_labels = train_val_test_sets(three_bed_flat_merged)\n",
    "X_train_two_bed_house_labels, X_val_two_bed_house_labels, X_test_two_bed_house_labels, y_train_two_bed_house_labels, y_val_two_bed_house_labels, y_test_two_bed_house_labels = train_val_test_sets(two_bed_house_merged)\n",
    "X_train_three_bed_house_labels, X_val_three_bed_house_labels, X_test_three_bed_house_labels, y_train_three_bed_house_labels, y_val_three_bed_house_labels, y_test_three_bed_house_labels = train_val_test_sets(three_bed_house_merged)\n",
    "X_train_four_bed_house_labels, X_val_four_bed_house_labels, X_test_four_bed_house_labels, y_train_four_bed_house_labels, y_val_four_bed_house_labels, y_test_four_bed_house_labels = train_val_test_sets(four_bed_house_merged)\n",
    "X_train_all_properties_labels, X_val_all_properties_labels, X_test_all_properties_labels, y_train_all_properties_labels, y_val_all_properties_labels, y_test_all_properties_labels = train_val_test_sets(all_properties_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_labels(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    \"\"\"\n",
    "    This function removes the year and suburb columns from each \n",
    "    of the train, val and test dataframes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Drop the specified columns from X dataframes\n",
    "    X_train = X_train.drop(columns=['suburb', 'year'])\n",
    "    X_val = X_val.drop(columns=['suburb', 'year'])\n",
    "    X_test = X_test.drop(columns=['suburb', 'year'])\n",
    "\n",
    "    # Drop the specified columns from y dataframes\n",
    "    y_train = y_train.drop(columns=['suburb', 'year'])\n",
    "    y_val = y_val.drop(columns=['suburb', 'year'])\n",
    "    y_test = y_test.drop(columns=['suburb', 'year'])\n",
    "    \n",
    "    # Return the modified dataframes without '_labels'\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "# For each dataset, apply the function\n",
    "X_train_one_bed, X_val_one_bed, X_test_one_bed, y_train_one_bed, y_val_one_bed, y_test_one_bed = drop_labels(\n",
    "    X_train_one_bed_labels, X_val_one_bed_labels, X_test_one_bed_labels, y_train_one_bed_labels, y_val_one_bed_labels, y_test_one_bed_labels\n",
    ")\n",
    "\n",
    "X_train_two_bed, X_val_two_bed, X_test_two_bed, y_train_two_bed, y_val_two_bed, y_test_two_bed = drop_labels(\n",
    "    X_train_two_bed_labels, X_val_two_bed_labels, X_test_two_bed_labels, y_train_two_bed_labels, y_val_two_bed_labels, y_test_two_bed_labels\n",
    ")\n",
    "\n",
    "X_train_three_bed, X_val_three_bed, X_test_three_bed, y_train_three_bed, y_val_three_bed, y_test_three_bed = drop_labels(\n",
    "    X_train_three_bed_labels, X_val_three_bed_labels, X_test_three_bed_labels, y_train_three_bed_labels, y_val_three_bed_labels, y_test_three_bed_labels\n",
    ")\n",
    "\n",
    "X_train_two_bed_house, X_val_two_bed_house, X_test_two_bed_house, y_train_two_bed_house, y_val_two_bed_house, y_test_two_bed_house = drop_labels(\n",
    "    X_train_two_bed_house_labels, X_val_two_bed_house_labels, X_test_two_bed_house_labels, y_train_two_bed_house_labels, y_val_two_bed_house_labels, y_test_two_bed_house_labels\n",
    ")\n",
    "\n",
    "X_train_three_bed_house, X_val_three_bed_house, X_test_three_bed_house, y_train_three_bed_house, y_val_three_bed_house, y_test_three_bed_house = drop_labels(\n",
    "    X_train_three_bed_house_labels, X_val_three_bed_house_labels, X_test_three_bed_house_labels, y_train_three_bed_house_labels, y_val_three_bed_house_labels, y_test_three_bed_house_labels\n",
    ")\n",
    "\n",
    "X_train_four_bed_house, X_val_four_bed_house, X_test_four_bed_house, y_train_four_bed_house, y_val_four_bed_house, y_test_four_bed_house = drop_labels(\n",
    "    X_train_four_bed_house_labels, X_val_four_bed_house_labels, X_test_four_bed_house_labels, y_train_four_bed_house_labels, y_val_four_bed_house_labels, y_test_four_bed_house_labels\n",
    ")\n",
    "\n",
    "X_train_all_properties, X_val_all_properties, X_test_all_properties, y_train_all_properties, y_val_all_properties, y_test_all_properties = drop_labels(\n",
    "    X_train_all_properties_labels, X_val_all_properties_labels, X_test_all_properties_labels, y_train_all_properties_labels, y_val_all_properties_labels, y_test_all_properties_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see all the X columns are the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'One Bed': 'Columns are the same in all three sets (train, validation, test).',\n",
       " 'Two Bed': 'Columns are the same in all three sets (train, validation, test).',\n",
       " 'Three Bed': 'Columns are the same in all three sets (train, validation, test).',\n",
       " 'Two Bed House': 'Columns are the same in all three sets (train, validation, test).',\n",
       " 'Three Bed House': 'Columns are the same in all three sets (train, validation, test).',\n",
       " 'Four Bed House': 'Columns are the same in all three sets (train, validation, test).',\n",
       " 'All Properties': 'Columns are the same in all three sets (train, validation, test).'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_feature_columns(train, val, test):\n",
    "    \"\"\"\n",
    "    This function compares columns of the training, validation, and \n",
    "    testing feature dataframes (X). A dictionary is then returned\n",
    "    indicating if any columns are missing in each set or if all\n",
    "    the colums are the same. \n",
    "    \"\"\"\n",
    "    comparison_result = {}\n",
    "    # Check if columns match between train, validation, and test sets\n",
    "    train_val_match = train.columns.equals(val.columns)\n",
    "    train_test_match = train.columns.equals(test.columns)\n",
    "    val_test_match = val.columns.equals(test.columns)\n",
    "    \n",
    "    if not (train_val_match and train_test_match and val_test_match):\n",
    "        missing_in_val = set(train.columns) - set(val.columns)\n",
    "        missing_in_train_val = set(val.columns) - set(train.columns)\n",
    "        missing_in_test = set(train.columns) - set(test.columns)\n",
    "        missing_in_train_test = set(test.columns) - set(train.columns)\n",
    "        missing_in_val_test = set(val.columns) - set(test.columns)\n",
    "        missing_in_test_val = set(test.columns) - set(val.columns)\n",
    "\n",
    "        comparison_result = {\n",
    "            \"Columns missing in validation set compared to train\": list(missing_in_val),\n",
    "            \"Columns missing in train set compared to validation\": list(missing_in_train_val),\n",
    "            \"Columns missing in test set compared to train\": list(missing_in_test),\n",
    "            \"Columns missing in train set compared to test\": list(missing_in_train_test),\n",
    "            \"Columns missing in test set compared to validation\": list(missing_in_val_test),\n",
    "            \"Columns missing in validation set compared to test\": list(missing_in_test_val),\n",
    "        }\n",
    "    else:\n",
    "        comparison_result = \"Columns are the same in all three sets (train, validation, test).\"\n",
    "\n",
    "    return comparison_result\n",
    "\n",
    "# List of training, validation, and testing DataFrames to compare\n",
    "feature_dfs = {\n",
    "    \"One Bed\": (X_train_one_bed, X_val_one_bed, X_test_one_bed),\n",
    "    \"Two Bed\": (X_train_two_bed, X_val_two_bed, X_test_two_bed),\n",
    "    \"Three Bed\": (X_train_three_bed, X_val_three_bed, X_test_three_bed),\n",
    "    \"Two Bed House\": (X_train_two_bed_house, X_val_two_bed_house, X_test_two_bed_house),\n",
    "    \"Three Bed House\": (X_train_three_bed_house, X_val_three_bed_house, X_test_three_bed_house),\n",
    "    \"Four Bed House\": (X_train_four_bed_house, X_val_four_bed_house, X_test_four_bed_house),\n",
    "    \"All Properties\": (X_train_all_properties, X_val_all_properties, X_test_all_properties)\n",
    "}\n",
    "\n",
    "# Compare columns for each triplet of training, validation, and testing sets\n",
    "comparison_results = {name: compare_feature_columns(train, val, test) for name, (train, val, test) in feature_dfs.items()}\n",
    "\n",
    "comparison_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dataframes to check for missing values\n",
    "dataframes = {\n",
    "    'X_train_one_bed': X_train_one_bed,\n",
    "    'X_val_one_bed': X_val_one_bed,\n",
    "    'X_test_one_bed': X_test_one_bed,\n",
    "    'y_train_one_bed': y_train_one_bed,\n",
    "    'y_val_one_bed': y_val_one_bed,\n",
    "    'y_test_one_bed': y_test_one_bed,\n",
    "    \n",
    "    'X_train_two_bed': X_train_two_bed,\n",
    "    'X_val_two_bed': X_val_two_bed,\n",
    "    'X_test_two_bed': X_test_two_bed,\n",
    "    'y_train_two_bed': y_train_two_bed,\n",
    "    'y_val_two_bed': y_val_two_bed,\n",
    "    'y_test_two_bed': y_test_two_bed,\n",
    "    \n",
    "    'X_train_three_bed': X_train_three_bed,\n",
    "    'X_val_three_bed': X_val_three_bed,\n",
    "    'X_test_three_bed': X_test_three_bed,\n",
    "    'y_train_three_bed': y_train_three_bed,\n",
    "    'y_val_three_bed': y_val_three_bed,\n",
    "    'y_test_three_bed': y_test_three_bed,\n",
    "    \n",
    "    'X_train_two_bed_house': X_train_two_bed_house,\n",
    "    'X_val_two_bed_house': X_val_two_bed_house,\n",
    "    'X_test_two_bed_house': X_test_two_bed_house,\n",
    "    'y_train_two_bed_house': y_train_two_bed_house,\n",
    "    'y_val_two_bed_house': y_val_two_bed_house,\n",
    "    'y_test_two_bed_house': y_test_two_bed_house,\n",
    "    \n",
    "    'X_train_three_bed_house': X_train_three_bed_house,\n",
    "    'X_val_three_bed_house': X_val_three_bed_house,\n",
    "    'X_test_three_bed_house': X_test_three_bed_house,\n",
    "    'y_train_three_bed_house': y_train_three_bed_house,\n",
    "    'y_val_three_bed_house': y_val_three_bed_house,\n",
    "    'y_test_three_bed_house': y_test_three_bed_house,\n",
    "    \n",
    "    'X_train_four_bed_house': X_train_four_bed_house,\n",
    "    'X_val_four_bed_house': X_val_four_bed_house,\n",
    "    'X_test_four_bed_house': X_test_four_bed_house,\n",
    "    'y_train_four_bed_house': y_train_four_bed_house,\n",
    "    'y_val_four_bed_house': y_val_four_bed_house,\n",
    "    'y_test_four_bed_house': y_test_four_bed_house,\n",
    "    \n",
    "    'X_train_all_properties': X_train_all_properties,\n",
    "    'X_val_all_properties': X_val_all_properties,\n",
    "    'X_test_all_properties': X_test_all_properties,\n",
    "    'y_train_all_properties': y_train_all_properties,\n",
    "    'y_val_all_properties': y_val_all_properties,\n",
    "    'y_test_all_properties': y_test_all_properties,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y_test_one_bed':       dec_median  jun_median  mar_median  sep_median\n",
      "9            NaN         NaN         NaN         NaN\n",
      "10           NaN         NaN         NaN         NaN\n",
      "11           NaN         NaN         NaN         NaN\n",
      "21           NaN         NaN         NaN         NaN\n",
      "22           NaN         NaN         NaN         NaN\n",
      "...          ...         ...         ...         ...\n",
      "1552         NaN         NaN         NaN         NaN\n",
      "1553         NaN         NaN         NaN         NaN\n",
      "1554         NaN         NaN         NaN         NaN\n",
      "1555         NaN         NaN         NaN         NaN\n",
      "1556         NaN         NaN         NaN         NaN\n",
      "\n",
      "[396 rows x 4 columns], 'y_test_two_bed':       dec_median  jun_median  mar_median  sep_median\n",
      "9            NaN         NaN         NaN         NaN\n",
      "10           NaN         NaN         NaN         NaN\n",
      "11           NaN         NaN         NaN         NaN\n",
      "21           NaN         NaN         NaN         NaN\n",
      "22           NaN         NaN         NaN         NaN\n",
      "...          ...         ...         ...         ...\n",
      "2002         NaN         NaN         NaN         NaN\n",
      "2003         NaN         NaN         NaN         NaN\n",
      "2013         NaN         NaN         NaN         NaN\n",
      "2014         NaN         NaN         NaN         NaN\n",
      "2015         NaN         NaN         NaN         NaN\n",
      "\n",
      "[504 rows x 4 columns], 'y_test_three_bed':       dec_median  jun_median  mar_median  sep_median\n",
      "9            NaN         NaN         NaN         NaN\n",
      "10           NaN         NaN         NaN         NaN\n",
      "11           NaN         NaN         NaN         NaN\n",
      "21           NaN         NaN         NaN         NaN\n",
      "22           NaN         NaN         NaN         NaN\n",
      "...          ...         ...         ...         ...\n",
      "1465         NaN         NaN         NaN         NaN\n",
      "1466         NaN         NaN         NaN         NaN\n",
      "1467         NaN         NaN         NaN         NaN\n",
      "1468         NaN         NaN         NaN         NaN\n",
      "1469         NaN         NaN         NaN         NaN\n",
      "\n",
      "[372 rows x 4 columns], 'y_test_two_bed_house':       dec_median  jun_median  mar_median  sep_median\n",
      "9            NaN         NaN         NaN         NaN\n",
      "10           NaN         NaN         NaN         NaN\n",
      "11           NaN         NaN         NaN         NaN\n",
      "21           NaN         NaN         NaN         NaN\n",
      "22           NaN         NaN         NaN         NaN\n",
      "...          ...         ...         ...         ...\n",
      "1849         NaN         NaN         NaN         NaN\n",
      "1850         NaN         NaN         NaN         NaN\n",
      "1851         NaN         NaN         NaN         NaN\n",
      "1852         NaN         NaN         NaN         NaN\n",
      "1853         NaN         NaN         NaN         NaN\n",
      "\n",
      "[477 rows x 4 columns], 'y_test_three_bed_house':       dec_median  jun_median  mar_median  sep_median\n",
      "9            NaN         NaN         NaN         NaN\n",
      "10           NaN         NaN         NaN         NaN\n",
      "11           NaN         NaN         NaN         NaN\n",
      "21           NaN         NaN         NaN         NaN\n",
      "22           NaN         NaN         NaN         NaN\n",
      "...          ...         ...         ...         ...\n",
      "2329         NaN         NaN         NaN         NaN\n",
      "2330         NaN         NaN         NaN         NaN\n",
      "2331         NaN         NaN         NaN         NaN\n",
      "2332         NaN         NaN         NaN         NaN\n",
      "2333         NaN         NaN         NaN         NaN\n",
      "\n",
      "[588 rows x 4 columns], 'y_test_four_bed_house':       dec_median  jun_median  mar_median  sep_median\n",
      "9            NaN         NaN         NaN         NaN\n",
      "10           NaN         NaN         NaN         NaN\n",
      "11           NaN         NaN         NaN         NaN\n",
      "21           NaN         NaN         NaN         NaN\n",
      "22           NaN         NaN         NaN         NaN\n",
      "...          ...         ...         ...         ...\n",
      "2038         NaN         NaN         NaN         NaN\n",
      "2039         NaN         NaN         NaN         NaN\n",
      "2040         NaN         NaN         NaN         NaN\n",
      "2041         NaN         NaN         NaN         NaN\n",
      "2042         NaN         NaN         NaN         NaN\n",
      "\n",
      "[513 rows x 4 columns], 'y_test_all_properties':       dec_median  jun_median  mar_median  sep_median\n",
      "9            NaN         NaN         NaN         NaN\n",
      "10           NaN         NaN         NaN         NaN\n",
      "11           NaN         NaN         NaN         NaN\n",
      "21           NaN         NaN         NaN         NaN\n",
      "22           NaN         NaN         NaN         NaN\n",
      "...          ...         ...         ...         ...\n",
      "2362         NaN         NaN         NaN         NaN\n",
      "2363         NaN         NaN         NaN         NaN\n",
      "2373         NaN         NaN         NaN         NaN\n",
      "2374         NaN         NaN         NaN         NaN\n",
      "2375         NaN         NaN         NaN         NaN\n",
      "\n",
      "[594 rows x 4 columns]}\n",
      "{'y_test_one_bed': dec_median    396\n",
      "jun_median    396\n",
      "mar_median    396\n",
      "sep_median    396\n",
      "dtype: int64, 'y_test_two_bed': dec_median    504\n",
      "jun_median    504\n",
      "mar_median    504\n",
      "sep_median    504\n",
      "dtype: int64, 'y_test_three_bed': dec_median    372\n",
      "jun_median    372\n",
      "mar_median    372\n",
      "sep_median    372\n",
      "dtype: int64, 'y_test_two_bed_house': dec_median    477\n",
      "jun_median    477\n",
      "mar_median    477\n",
      "sep_median    477\n",
      "dtype: int64, 'y_test_three_bed_house': dec_median    588\n",
      "jun_median    588\n",
      "mar_median    588\n",
      "sep_median    588\n",
      "dtype: int64, 'y_test_four_bed_house': dec_median    513\n",
      "jun_median    513\n",
      "mar_median    513\n",
      "sep_median    513\n",
      "dtype: int64, 'y_test_all_properties': dec_median    594\n",
      "jun_median    594\n",
      "mar_median    594\n",
      "sep_median    594\n",
      "dtype: int64}\n"
     ]
    }
   ],
   "source": [
    "# Collecting rows with missing values for each dataframe\n",
    "missing_rows_summary = {}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    rows_with_missing = df[df.isnull().any(axis=1)]\n",
    "    if not rows_with_missing.empty:\n",
    "        missing_rows_summary[name] = rows_with_missing\n",
    "\n",
    "print(missing_rows_summary)\n",
    "\n",
    "# Check for missing values in each dataframe by columns \n",
    "missing_values_summary = {}\n",
    "for name, df in dataframes.items():\n",
    "    missing_values = df.isnull().sum()\n",
    "    columns_with_missing = missing_values[missing_values > 0]\n",
    "    if not columns_with_missing.empty:\n",
    "        missing_values_summary[name] = columns_with_missing\n",
    "\n",
    "print(missing_values_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of all training, validation, and test sets\n",
    "ML_dfs = [\n",
    "    (X_train_one_bed, X_val_one_bed, X_test_one_bed, y_train_one_bed, y_val_one_bed, y_test_one_bed),\n",
    "    (X_train_two_bed, X_val_two_bed, X_test_two_bed, y_train_two_bed, y_val_two_bed, y_test_two_bed),\n",
    "    (X_train_three_bed, X_val_three_bed, X_test_three_bed, y_train_three_bed, y_val_three_bed, y_test_three_bed),\n",
    "    (X_train_two_bed_house, X_val_two_bed_house, X_test_two_bed_house, y_train_two_bed_house, y_val_two_bed_house, y_test_two_bed_house),\n",
    "    (X_train_three_bed_house, X_val_three_bed_house, X_test_three_bed_house, y_train_three_bed_house, y_val_three_bed_house, y_test_three_bed_house),\n",
    "    (X_train_four_bed_house, X_val_four_bed_house, X_test_four_bed_house, y_train_four_bed_house, y_val_four_bed_house, y_test_four_bed_house),\n",
    "    (X_train_all_properties, X_val_all_properties, X_test_all_properties, y_train_all_properties, y_val_all_properties, y_test_all_properties),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees\n",
    "    'max_depth': [5, 10, 15, None],  # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "}\n",
    "\n",
    "def rfecv_with_random_forest(X_train, X_val, X_test, y_train):\n",
    "    \"\"\"\n",
    "    Apply Recursive Feature Elimination with Cross-Validation (RFECV) using\n",
    "    Random Forest as the estimator to automatically select the optimal number\n",
    "    of features, then use GridSearchCV to fine-tune hyperparameters on the reduced feature set.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: Training feature set\n",
    "    X_val: Validation feature set\n",
    "    X_test: Test feature set\n",
    "    y_train: Training labels (target)\n",
    "    \n",
    "    Returns:\n",
    "    X_train_rfecv, X_val_rfecv, X_test_rfecv: Reduced datasets\n",
    "    best_rf: Best tuned Random Forest model after feature selection\n",
    "    \"\"\"\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize the Random Forest model\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # Use RFECV to automatically select the optimal number of features\n",
    "    rfecv = RFECV(estimator=rf_model, step=1, cv=KFold(5), scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    rfecv.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Transform the datasets based on the selected features\n",
    "    X_train_rfecv = rfecv.transform(X_train_scaled)\n",
    "    X_val_rfecv = rfecv.transform(X_val_scaled)\n",
    "    X_test_rfecv = rfecv.transform(X_test_scaled)\n",
    "\n",
    "    # Perform hyperparameter tuning using GridSearchCV on the reduced feature set\n",
    "    rf_after_rfecv = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(rf_after_rfecv, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    grid_search.fit(X_train_rfecv, y_train)\n",
    "    \n",
    "    # Select the best Random Forest model based on GridSearchCV\n",
    "    best_rf = grid_search.best_estimator_\n",
    "\n",
    "    # Get the selected feature indices and names\n",
    "    selected_features = rfecv.get_support(indices=True)\n",
    "    selected_feature_names = [X_train.columns[i] for i in selected_features]  # Use X_train columns\n",
    "\n",
    "    # Get the feature importance values from the trained Random Forest model (best_rf)\n",
    "    importances = best_rf.feature_importances_\n",
    "\n",
    "    # Pair selected features with their corresponding importance values\n",
    "    feature_importance_pairs = list(zip(selected_feature_names, importances))\n",
    "\n",
    "    # Sort the features by importance values in descending order\n",
    "    sorted_features = sorted(feature_importance_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print the sorted features with their importance values\n",
    "    print(f\"Optimal number of features selected: {rfecv.n_features_}\")\n",
    "    print(f\"Selected feature names: {selected_feature_names}\")\n",
    "    print(f\"Selected features sorted by importance:\")\n",
    "    for feature, importance in sorted_features:\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "    return X_train_rfecv, X_val_rfecv, X_test_rfecv, best_rf, selected_feature_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property Type: one_bed_flat\n",
      "Optimal number of features selected: 74\n",
      "Selected feature names: ['offence_division_1', 'offence_division_2', 'offence_division_3', 'offence_division_4', 'offence_division_5', 'offence_division_6', 'hi_1_149_tot', 'hi_150_299_tot', 'hi_300_399_tot', 'hi_400_499_tot', 'hi_500_649_tot', 'hi_650_799_tot', 'hi_800_999_tot', 'hi_1000_1249_tot', 'hi_1250_1499_tot', 'hi_1500_1749_tot', 'hi_1750_1999_tot', 'hi_2000_2499_tot', 'hi_2500_2999_tot', 'hi_3000_3499_tot', 'hi_3500_3999_tot', 'hi_4000_more_tot', 'erp', 'primary_school_count', 'secondary_school_count', 'avg_primary_school_rank', 'avg_secondary_school_rank', 'has_secondary_school', 'total_education_count', 'commercial_areas', 'forest', 'industrial_areas', 'nature_reserve', 'park', 'residential_areas', 'retail_areas', 'landuse_mode', 'cycleway', 'main_roads', 'motorway', 'residential_roads', 'track', 'walking_paths', 'roads_mode', 'beach', 'nature_mode', 'accommodation', 'culture_and_leisure', 'financial_institutions', 'food_and_beverage', 'healthcare', 'public_facilities', 'shopping_and_retail', 'tourism_and_attractions', 'pois_mode', 'pofw_count', 'pofw_mode', 'distance_to_fire_station', 'distance_to_hospital', 'distance_to_hotel', 'distance_to_kindergarten', 'distance_to_library', 'distance_to_mall', 'distance_to_park', 'distance_to_police', 'distance_to_restaurant', 'distance_to_supermarket', 'nearest_transport_avg_distance', 'distance_to_cbd', 'median_parkings', 'furnished_count', 'unfurnished_count', 'pets_allowed', 'pets_not_allowed']\n",
      "Selected features sorted by importance:\n",
      "distance_to_cbd: 0.7284\n",
      "hi_4000_more_tot: 0.0705\n",
      "main_roads: 0.0092\n",
      "distance_to_hotel: 0.0085\n",
      "offence_division_4: 0.0084\n",
      "pets_allowed: 0.0068\n",
      "offence_division_6: 0.0067\n",
      "offence_division_3: 0.0064\n",
      "industrial_areas: 0.0063\n",
      "hi_3000_3499_tot: 0.0058\n",
      "retail_areas: 0.0054\n",
      "offence_division_2: 0.0053\n",
      "hi_3500_3999_tot: 0.0052\n",
      "nearest_transport_avg_distance: 0.0050\n",
      "erp: 0.0048\n",
      "hi_500_649_tot: 0.0046\n",
      "hi_150_299_tot: 0.0046\n",
      "motorway: 0.0045\n",
      "hi_300_399_tot: 0.0042\n",
      "tourism_and_attractions: 0.0038\n",
      "avg_secondary_school_rank: 0.0038\n",
      "offence_division_1: 0.0037\n",
      "hi_1_149_tot: 0.0036\n",
      "hi_1500_1749_tot: 0.0036\n",
      "offence_division_5: 0.0036\n",
      "walking_paths: 0.0035\n",
      "distance_to_mall: 0.0035\n",
      "accommodation: 0.0031\n",
      "residential_areas: 0.0031\n",
      "pofw_count: 0.0030\n",
      "hi_400_499_tot: 0.0030\n",
      "distance_to_supermarket: 0.0028\n",
      "hi_2500_2999_tot: 0.0028\n",
      "roads_mode: 0.0025\n",
      "financial_institutions: 0.0024\n",
      "hi_800_999_tot: 0.0023\n",
      "hi_1000_1249_tot: 0.0023\n",
      "culture_and_leisure: 0.0022\n",
      "median_parkings: 0.0022\n",
      "avg_primary_school_rank: 0.0021\n",
      "hi_1750_1999_tot: 0.0021\n",
      "healthcare: 0.0020\n",
      "hi_2000_2499_tot: 0.0020\n",
      "distance_to_fire_station: 0.0019\n",
      "hi_650_799_tot: 0.0018\n",
      "hi_1250_1499_tot: 0.0018\n",
      "park: 0.0016\n",
      "public_facilities: 0.0016\n",
      "residential_roads: 0.0016\n",
      "distance_to_hospital: 0.0015\n",
      "shopping_and_retail: 0.0015\n",
      "distance_to_restaurant: 0.0014\n",
      "food_and_beverage: 0.0014\n",
      "cycleway: 0.0013\n",
      "forest: 0.0012\n",
      "commercial_areas: 0.0010\n",
      "distance_to_police: 0.0009\n",
      "beach: 0.0009\n",
      "total_education_count: 0.0009\n",
      "landuse_mode: 0.0008\n",
      "pets_not_allowed: 0.0008\n",
      "nature_reserve: 0.0007\n",
      "distance_to_library: 0.0007\n",
      "track: 0.0007\n",
      "distance_to_kindergarten: 0.0007\n",
      "unfurnished_count: 0.0007\n",
      "secondary_school_count: 0.0007\n",
      "distance_to_park: 0.0006\n",
      "has_secondary_school: 0.0005\n",
      "primary_school_count: 0.0003\n",
      "furnished_count: 0.0002\n",
      "pois_mode: 0.0002\n",
      "pofw_mode: 0.0002\n",
      "nature_mode: 0.0002\n",
      "Best n_estimators: 200, Best max_depth: 10\n",
      "Validation MSE: 4173.5858, R^2: 0.2650, Validation MAE: 48.0716\n",
      "Predictions for 2025-2027: [[465.1055874  458.03153436 452.67564257 480.43320309]\n",
      " [465.79872877 458.95735282 453.68560537 481.68724327]\n",
      " [466.67015734 459.48881115 454.2151887  482.61566589]\n",
      " ...\n",
      " [278.16655347 271.10429396 267.70706704 277.72239589]\n",
      " [280.57673222 273.22700428 269.60457065 279.11221208]\n",
      " [288.25448264 279.50151397 275.81325973 283.7641906 ]]\n",
      "\n",
      "\n",
      "Property Type: two_bed_flat\n",
      "Optimal number of features selected: 55\n",
      "Selected feature names: ['offence_division_1', 'offence_division_2', 'offence_division_3', 'offence_division_4', 'offence_division_5', 'offence_division_6', 'hi_1_149_tot', 'hi_150_299_tot', 'hi_300_399_tot', 'hi_400_499_tot', 'hi_500_649_tot', 'hi_650_799_tot', 'hi_800_999_tot', 'hi_1000_1249_tot', 'hi_1250_1499_tot', 'hi_1500_1749_tot', 'hi_1750_1999_tot', 'hi_2000_2499_tot', 'hi_2500_2999_tot', 'hi_3000_3499_tot', 'hi_3500_3999_tot', 'hi_4000_more_tot', 'erp', 'avg_primary_school_rank', 'avg_secondary_school_rank', 'forest', 'industrial_areas', 'nature_reserve', 'park', 'residential_areas', 'retail_areas', 'landuse_mode', 'cycleway', 'main_roads', 'motorway', 'residential_roads', 'walking_paths', 'beach', 'accommodation', 'culture_and_leisure', 'financial_institutions', 'food_and_beverage', 'public_facilities', 'shopping_and_retail', 'tourism_and_attractions', 'pofw_count', 'distance_to_library', 'distance_to_park', 'distance_to_restaurant', 'distance_to_supermarket', 'nearest_transport_avg_distance', 'distance_to_cbd', 'furnished_count', 'unfurnished_count', 'pets_not_allowed']\n",
      "Selected features sorted by importance:\n",
      "distance_to_cbd: 0.7702\n",
      "hi_4000_more_tot: 0.0432\n",
      "main_roads: 0.0100\n",
      "financial_institutions: 0.0093\n",
      "offence_division_6: 0.0087\n",
      "hi_3000_3499_tot: 0.0071\n",
      "hi_3500_3999_tot: 0.0070\n",
      "offence_division_2: 0.0068\n",
      "offence_division_4: 0.0067\n",
      "residential_areas: 0.0066\n",
      "offence_division_1: 0.0065\n",
      "beach: 0.0065\n",
      "avg_secondary_school_rank: 0.0062\n",
      "hi_150_299_tot: 0.0057\n",
      "industrial_areas: 0.0056\n",
      "accommodation: 0.0048\n",
      "offence_division_5: 0.0043\n",
      "nearest_transport_avg_distance: 0.0042\n",
      "residential_roads: 0.0039\n",
      "food_and_beverage: 0.0035\n",
      "hi_300_399_tot: 0.0034\n",
      "offence_division_3: 0.0034\n",
      "hi_500_649_tot: 0.0032\n",
      "hi_1750_1999_tot: 0.0029\n",
      "nature_reserve: 0.0029\n",
      "hi_400_499_tot: 0.0029\n",
      "hi_650_799_tot: 0.0028\n",
      "distance_to_restaurant: 0.0028\n",
      "hi_1_149_tot: 0.0028\n",
      "hi_2500_2999_tot: 0.0027\n",
      "erp: 0.0026\n",
      "hi_1000_1249_tot: 0.0024\n",
      "hi_2000_2499_tot: 0.0023\n",
      "motorway: 0.0022\n",
      "pofw_count: 0.0022\n",
      "hi_800_999_tot: 0.0021\n",
      "distance_to_park: 0.0020\n",
      "distance_to_supermarket: 0.0020\n",
      "cycleway: 0.0020\n",
      "distance_to_library: 0.0019\n",
      "tourism_and_attractions: 0.0018\n",
      "unfurnished_count: 0.0017\n",
      "landuse_mode: 0.0017\n",
      "hi_1500_1749_tot: 0.0017\n",
      "pets_not_allowed: 0.0016\n",
      "hi_1250_1499_tot: 0.0016\n",
      "public_facilities: 0.0015\n",
      "avg_primary_school_rank: 0.0015\n",
      "shopping_and_retail: 0.0015\n",
      "park: 0.0013\n",
      "walking_paths: 0.0013\n",
      "retail_areas: 0.0012\n",
      "furnished_count: 0.0012\n",
      "forest: 0.0011\n",
      "culture_and_leisure: 0.0010\n",
      "Best n_estimators: 200, Best max_depth: None\n",
      "Validation MSE: 6230.4811, R^2: 0.2774, Validation MAE: 62.6590\n",
      "Predictions for 2025-2027: [[622.85   616.335  611.125  643.9625]\n",
      " [624.575  618.26   613.     646.3375]\n",
      " [622.8    616.315  611.625  642.4625]\n",
      " ...\n",
      " [472.325  465.56   463.195  509.9475]\n",
      " [476.46   467.92   464.61   505.845 ]\n",
      " [483.2    472.655  468.415  504.565 ]]\n",
      "\n",
      "\n",
      "Property Type: three_bed_flat\n",
      "Optimal number of features selected: 3\n",
      "Selected feature names: ['offence_division_1', 'hi_4000_more_tot', 'distance_to_cbd']\n",
      "Selected features sorted by importance:\n",
      "distance_to_cbd: 0.8002\n",
      "offence_division_1: 0.1104\n",
      "hi_4000_more_tot: 0.0894\n",
      "Best n_estimators: 200, Best max_depth: 10\n",
      "Validation MSE: 14481.7931, R^2: 0.5425, Validation MAE: 86.7218\n",
      "Predictions for 2025-2027: [[853.41433481 841.99880054 833.85112603 859.56749766]\n",
      " [856.46477529 844.61364956 836.34792617 861.49303635]\n",
      " [861.94187551 848.89239128 839.96749246 867.603285  ]\n",
      " ...\n",
      " [373.99967437 364.69195018 362.81346973 371.65348152]\n",
      " [395.94888737 388.48319934 385.97566967 396.18983569]\n",
      " [398.345531   391.81553318 389.5009879  398.74588103]]\n",
      "\n",
      "\n",
      "Property Type: two_bed_house\n",
      "Optimal number of features selected: 22\n",
      "Selected feature names: ['offence_division_1', 'offence_division_4', 'offence_division_5', 'offence_division_6', 'hi_150_299_tot', 'hi_650_799_tot', 'hi_1750_1999_tot', 'hi_3000_3499_tot', 'hi_3500_3999_tot', 'hi_4000_more_tot', 'erp', 'forest', 'park', 'residential_areas', 'cycleway', 'main_roads', 'residential_roads', 'walking_paths', 'distance_to_park', 'nearest_transport_avg_distance', 'distance_to_cbd', 'unfurnished_count']\n",
      "Selected features sorted by importance:\n",
      "distance_to_cbd: 0.8161\n",
      "hi_4000_more_tot: 0.0470\n",
      "offence_division_1: 0.0166\n",
      "offence_division_5: 0.0163\n",
      "hi_1750_1999_tot: 0.0107\n",
      "residential_areas: 0.0103\n",
      "nearest_transport_avg_distance: 0.0099\n",
      "main_roads: 0.0083\n",
      "hi_3000_3499_tot: 0.0064\n",
      "hi_650_799_tot: 0.0060\n",
      "distance_to_park: 0.0056\n",
      "park: 0.0054\n",
      "residential_roads: 0.0052\n",
      "hi_150_299_tot: 0.0052\n",
      "offence_division_6: 0.0048\n",
      "walking_paths: 0.0044\n",
      "cycleway: 0.0042\n",
      "unfurnished_count: 0.0039\n",
      "hi_3500_3999_tot: 0.0036\n",
      "offence_division_4: 0.0034\n",
      "erp: 0.0034\n",
      "forest: 0.0033\n",
      "Best n_estimators: 200, Best max_depth: 15\n",
      "Validation MSE: 5562.5464, R^2: 0.6127, Validation MAE: 56.5227\n",
      "Predictions for 2025-2027: [[693.045  687.355  683.45   697.4475]\n",
      " [696.91   691.49   688.27   704.9575]\n",
      " [698.74   694.425  691.27   714.07  ]\n",
      " ...\n",
      " [705.005  699.155  694.455  817.9925]\n",
      " [706.035  700.42   696.175  820.7925]\n",
      " [707.105  702.505  698.89   852.1175]]\n",
      "\n",
      "\n",
      "Property Type: three_bed_house\n",
      "Optimal number of features selected: 11\n",
      "Selected feature names: ['offence_division_1', 'hi_400_499_tot', 'hi_2500_2999_tot', 'hi_4000_more_tot', 'park', 'residential_areas', 'main_roads', 'accommodation', 'food_and_beverage', 'nearest_transport_avg_distance', 'distance_to_cbd']\n",
      "Selected features sorted by importance:\n",
      "distance_to_cbd: 0.7766\n",
      "hi_4000_more_tot: 0.0732\n",
      "main_roads: 0.0250\n",
      "residential_areas: 0.0227\n",
      "offence_division_1: 0.0206\n",
      "accommodation: 0.0159\n",
      "nearest_transport_avg_distance: 0.0153\n",
      "food_and_beverage: 0.0130\n",
      "park: 0.0127\n",
      "hi_400_499_tot: 0.0127\n",
      "hi_2500_2999_tot: 0.0123\n",
      "Best n_estimators: 100, Best max_depth: 15\n",
      "Validation MSE: 7774.0070, R^2: 0.7491, Validation MAE: 67.7412\n",
      "Predictions for 2025-2027: [[842.74725447 834.71091042 835.72569669 863.58320968]\n",
      " [853.14775447 842.32624376 840.66319669 874.71920968]\n",
      " [878.83575447 867.15646598 865.84875225 918.25854301]\n",
      " ...\n",
      " [856.04666667 848.69666667 841.09333333 859.055     ]\n",
      " [854.15666667 847.44666667 839.50333333 858.185     ]\n",
      " [876.05666667 869.76666667 859.38333333 878.885     ]]\n",
      "\n",
      "\n",
      "Property Type: four_bed_house\n",
      "Optimal number of features selected: 6\n",
      "Selected feature names: ['offence_division_1', 'hi_300_399_tot', 'hi_4000_more_tot', 'residential_areas', 'accommodation', 'distance_to_cbd']\n",
      "Selected features sorted by importance:\n",
      "distance_to_cbd: 0.7083\n",
      "hi_4000_more_tot: 0.0798\n",
      "residential_areas: 0.0641\n",
      "accommodation: 0.0563\n",
      "offence_division_1: 0.0468\n",
      "hi_300_399_tot: 0.0446\n",
      "Best n_estimators: 200, Best max_depth: 15\n",
      "Validation MSE: 17130.1610, R^2: 0.7529, Validation MAE: 96.8073\n",
      "Predictions for 2025-2027: [[1426.89765115 1399.02365693 1376.01318416 1753.39827489]\n",
      " [1432.06681782 1407.49907359 1381.56610083 1764.05027489]\n",
      " [1431.45431782 1406.69282359 1380.59110083 1761.61277489]\n",
      " ...\n",
      " [1146.80592659 1147.89188889 1136.37323214 1166.61480952]\n",
      " [1193.60523431 1179.59193092 1168.92986364 1213.2149596 ]\n",
      " [1185.71114881 1174.48104563 1167.6983869  1205.69835218]]\n",
      "\n",
      "\n",
      "Property Type: all_properties\n",
      "Optimal number of features selected: 23\n",
      "Selected feature names: ['offence_division_1', 'offence_division_4', 'offence_division_5', 'hi_1_149_tot', 'hi_150_299_tot', 'hi_300_399_tot', 'hi_400_499_tot', 'hi_650_799_tot', 'hi_800_999_tot', 'hi_1000_1249_tot', 'hi_1250_1499_tot', 'hi_2500_2999_tot', 'hi_3000_3499_tot', 'hi_4000_more_tot', 'residential_areas', 'main_roads', 'residential_roads', 'walking_paths', 'beach', 'distance_to_kindergarten', 'distance_to_library', 'distance_to_restaurant', 'distance_to_cbd']\n",
      "Selected features sorted by importance:\n",
      "distance_to_cbd: 0.4221\n",
      "hi_4000_more_tot: 0.2252\n",
      "hi_650_799_tot: 0.0376\n",
      "residential_areas: 0.0248\n",
      "hi_800_999_tot: 0.0202\n",
      "hi_2500_2999_tot: 0.0201\n",
      "main_roads: 0.0192\n",
      "hi_1250_1499_tot: 0.0183\n",
      "distance_to_kindergarten: 0.0178\n",
      "hi_3000_3499_tot: 0.0175\n",
      "distance_to_restaurant: 0.0167\n",
      "beach: 0.0155\n",
      "walking_paths: 0.0150\n",
      "hi_150_299_tot: 0.0149\n",
      "hi_1_149_tot: 0.0148\n",
      "offence_division_5: 0.0143\n",
      "residential_roads: 0.0140\n",
      "hi_300_399_tot: 0.0135\n",
      "offence_division_1: 0.0133\n",
      "hi_400_499_tot: 0.0131\n",
      "offence_division_4: 0.0110\n",
      "hi_1000_1249_tot: 0.0106\n",
      "distance_to_library: 0.0104\n",
      "Best n_estimators: 200, Best max_depth: 15\n",
      "Validation MSE: 7251.3753, R^2: 0.2020, Validation MAE: 65.1842\n",
      "Predictions for 2025-2027: [[584.50166667 579.09116667 577.80416667 638.42716667]\n",
      " [583.1125     576.40775893 574.62388393 631.73822321]\n",
      " [604.3675     596.78325893 594.43138393 654.93272321]\n",
      " ...\n",
      " [589.81791667 583.59905104 581.40002193 690.01617225]\n",
      " [594.73       588.54378788 586.29       703.78007576]\n",
      " [595.71       589.83878788 587.7        707.01757576]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialise the predictions dictionary and MAE list\n",
    "predictions_dict = {}\n",
    "mae_list = []\n",
    "\n",
    "# Property Types\n",
    "property_types = ['one_bed_flat', 'two_bed_flat', 'three_bed_flat', \n",
    "                  'two_bed_house', 'three_bed_house', 'four_bed_house', 'all_properties']\n",
    "\n",
    "# Loop through each set, perform RFE, and predict using the tuned Random Forest model\n",
    "for i, (X_train, X_val, X_test, y_train, y_val, y_test) in enumerate(ML_dfs):\n",
    "    print(f\"Property Type: {property_types[i]}\")\n",
    "    # Perform feature selection and get the best model\n",
    "    X_train_rfecv, X_val_rfecv, X_test_rfecv, best_rf, selected_feature_names = rfecv_with_random_forest(\n",
    "        X_train, X_val, X_test, y_train\n",
    "    )\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    y_val_pred = best_rf.predict(X_val_rfecv)\n",
    "    val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "    val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "    val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "    # Save MAE\n",
    "    mae_list.append(val_mae)\n",
    "    \n",
    "    # Print the validation results\n",
    "    print(f\"Best n_estimators: {best_rf.n_estimators}, Best max_depth: {best_rf.max_depth}\")\n",
    "    print(f\"Validation MSE: {val_mse:.4f}, R^2: {val_r2:.4f}, Validation MAE: {val_mae:.4f}\")\n",
    "    \n",
    "    # Combine the training and validation sets for final model training\n",
    "    X_train_val_rfecv = np.vstack((X_train_rfecv, X_val_rfecv))\n",
    "    y_train_val = np.concatenate((y_train, y_val))\n",
    "    \n",
    "    # Retrain the model using the combined training and validation sets\n",
    "    best_rf.fit(X_train_val_rfecv, y_train_val)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_test_pred = best_rf.predict(X_test_rfecv)\n",
    "    \n",
    "    # Store predictions in the dictionary with dataset index as key\n",
    "    predictions_dict[f'X_test_{i+1}_predictions'] = y_test_pred\n",
    "    \n",
    "    # Print the predictions for the test set\n",
    "    print(f\"Predictions for 2025-2027: {y_test_pred}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path\n",
    "base_path = '../data/curated/predictions'\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved one_bed_flat with 'year', 'suburb', and predictions.\n",
      "Saved two_bed_flat with 'year', 'suburb', and predictions.\n",
      "Saved three_bed_flat with 'year', 'suburb', and predictions.\n",
      "Saved two_bed_house with 'year', 'suburb', and predictions.\n",
      "Saved three_bed_house with 'year', 'suburb', and predictions.\n",
      "Saved four_bed_house with 'year', 'suburb', and predictions.\n",
      "Saved all_properties with 'year', 'suburb', and predictions.\n"
     ]
    }
   ],
   "source": [
    "# Prediction Column Names\n",
    "column_names = ['dec_median', 'jun_median', 'mar_median', 'sep_median']\n",
    "\n",
    "# labelled_dfs corresponds to the datasets with labels for each property type\n",
    "labelled_dfs = [X_test_one_bed_labels, X_test_two_bed_labels, X_test_three_bed_labels, \n",
    "                X_test_two_bed_house_labels, X_test_three_bed_house_labels, \n",
    "                X_test_four_bed_house_labels, X_test_all_properties_labels]\n",
    "\n",
    "# Iterate through the predictions dictionary and labelled DataFrames\n",
    "for i, (key, value) in enumerate(predictions_dict.items()):\n",
    "    # Select only the 'year' and 'suburb' columns from the labelled_dfs\n",
    "    labelled_df_subset = labelled_dfs[i][['suburb', 'year']]\n",
    "\n",
    "    # Initialise an empty DataFrame for the predictions\n",
    "    predictions_df = pd.DataFrame()\n",
    "\n",
    "    # value is a 2D array with multiple rows and 4 columns (n_samples, 4)\n",
    "    # Add each column using the custom names for the median values\n",
    "    for j in range(value.shape[1]):\n",
    "        predictions_df[column_names[j]] = value[:, j]\n",
    "\n",
    "    # Reset the index for both DataFrames to ensure proper alignment\n",
    "    labelled_df_subset = labelled_df_subset.reset_index(drop=True)\n",
    "    predictions_df = predictions_df.reset_index(drop=True)\n",
    "    \n",
    "    # Concatenate the 'year' and 'suburb' columns with the predictions_df\n",
    "    labelled_with_predictions = pd.concat([labelled_df_subset, predictions_df], axis=1)\n",
    "\n",
    "    # Save the new DataFrame with only 'year', 'suburb', and predictions to a CSV file\n",
    "    labelled_with_predictions.to_csv(f\"../data/curated/predictions/{property_types[i]}_predictions.csv\", index=False)\n",
    "\n",
    "    # Print confirmation\n",
    "    print(f\"Saved {property_types[i]} with 'year', 'suburb', and predictions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE list has been saved to '../data/curated/predictions/mae.csv'\n"
     ]
    }
   ],
   "source": [
    "# Convert the MAE list to a pandas DataFrame\n",
    "mae_df = pd.DataFrame(mae_list, columns=['MAE'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "mae_df.to_csv(\"../data/curated/predictions/mae.csv\", index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"MAE list has been saved to '../data/curated/predictions/mae.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
