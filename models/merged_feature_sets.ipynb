{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rental History Data\n",
    "one_bed_flat = pd.read_csv('../data/curated/rental_history/one_bed_flat.csv')\n",
    "two_bed_flat = pd.read_csv('../data/curated/rental_history/two_bed_flat.csv')\n",
    "three_bed_flat = pd.read_csv('../data/curated/rental_history/three_bed_flat.csv')\n",
    "two_bed_house = pd.read_csv('../data/curated/rental_history/two_bed_house.csv')\n",
    "three_bed_house = pd.read_csv('../data/curated/rental_history/three_bed_house.csv')\n",
    "four_bed_house = pd.read_csv('../data/curated/rental_history/four_bed_house.csv')\n",
    "all_properties = pd.read_csv('../data/curated/rental_history/all_properties.csv')\n",
    "\n",
    "# Domain Rental Data\n",
    "domain_one_bed_flat = pd.read_csv('../data/curated/domain/domain_one_bed_flat_rent.csv')\n",
    "domain_two_bed_flat = pd.read_csv('../data/curated/domain/domain_two_bed_flat_rent.csv')\n",
    "domain_three_bed_flat = pd.read_csv('../data/curated/domain/domain_three_bed_flat_rent.csv')\n",
    "domain_two_bed_house = pd.read_csv('../data/curated/domain/domain_two_bed_house_rent.csv')\n",
    "domain_three_bed_house = pd.read_csv('../data/curated/domain/domain_three_bed_house_rent.csv')\n",
    "domain_four_bed_house = pd.read_csv('../data/curated/domain/domain_four_bed_house_rent.csv')\n",
    "domain_all_properties = pd.read_csv('../data/curated/domain/domain_all_properties_rent.csv')\n",
    "\n",
    "# Other engineered feature sets \n",
    "crimes = pd.read_csv('../data/curated/crimes.csv')\n",
    "population = pd.read_csv('../data/curated/population.csv')\n",
    "education = pd.read_csv('../data/curated/education.csv')\n",
    "urban_landmarks = pd.read_csv('../data/curated/urban_landmarks.csv')\n",
    "pt_distances = pd.read_csv('../data/curated/suburb_transport_distances.csv')\n",
    "income = pd.read_csv('../data/curated/income.csv')\n",
    "\n",
    "# Livability Index data \n",
    "livability_one_bed_flat = pd.read_csv('../data/curated/livability/livability_one_bed_flat.csv')\n",
    "livability_two_bed_flat = pd.read_csv('../data/curated/livability/livability_two_bed_flat.csv')\n",
    "livability_three_bed_flat = pd.read_csv('../data/curated/livability/livability_three_bed_flat.csv')\n",
    "livability_two_bed_house = pd.read_csv('../data/curated/livability/livability_two_bed_house.csv')\n",
    "livability_three_bed_house = pd.read_csv('../data/curated/livability/livability_three_bed_house.csv')\n",
    "livability_four_bed_house = pd.read_csv('../data/curated/livability/livability_four_bed_house.csv')\n",
    "livability_all_properties = pd.read_csv('../data/curated/livability/livability_all_properties.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting Rental Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_domain_df(df):\n",
    "    \"\"\"\n",
    "    This function cleans the domain dataframes by removing\n",
    "    the 'Unnamed:' column, renaming median_rent to 'sep_median'\n",
    "    (for a standardised column name as in rental history dfs) and\n",
    "    also creates a year column and inputs the relevant year that\n",
    "    the data is from - 2024. \n",
    "    \"\"\"\n",
    "\n",
    "    # Drop columns that contain 'Unnamed:' in their name\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed:')]\n",
    "    \n",
    "    # Rename the 'median_rent' column to 'sep_median'\n",
    "    if 'median_rent' in df.columns:\n",
    "        df = df.rename(columns={'median_rent': 'sep_median'})\n",
    "    \n",
    "    # Add a 'year' column with value 2024 for each row\n",
    "    df['year'] = 2024\n",
    "\n",
    "    # Reorder columns to make 'year' the second column\n",
    "    cols = list(df.columns)\n",
    "    cols.insert(1, cols.pop(cols.index('year')))\n",
    "    df = df[cols]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the clean_domain_df function to all the domain dataframes\n",
    "domain_one_bed_flat = clean_domain_df(domain_one_bed_flat)\n",
    "domain_two_bed_flat = clean_domain_df(domain_two_bed_flat)\n",
    "domain_three_bed_flat = clean_domain_df(domain_three_bed_flat)\n",
    "domain_two_bed_house = clean_domain_df(domain_two_bed_house)\n",
    "domain_three_bed_house = clean_domain_df(domain_three_bed_house)\n",
    "domain_four_bed_house = clean_domain_df(domain_four_bed_house)\n",
    "domain_all_properties = clean_domain_df(domain_all_properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute the Sep median price from scraped properties into the rental history dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_sep_2024_rental_data(rental_history_df, domain_df):\n",
    "    \"\"\"\n",
    "    This function retrieves all the median rental prices in \n",
    "    September from the domain dataframes and then imputes\n",
    "    them into the rental history dataframes where the year\n",
    "    is 2024 and month is September. \n",
    "    \"\"\"\n",
    "\n",
    "    # Merge rental_history_df with domain_df on 'suburb' to keep all years from rental_history_df\n",
    "    merged_df = pd.merge(rental_history_df, domain_df[['suburb', 'year', 'sep_median']],\n",
    "                         on=['suburb'], how='left', suffixes=('', '_domain'))\n",
    "    \n",
    "    # Replace sep_median values with domain values only for rows where year == 2024\n",
    "    condition = (merged_df['year'] == 2024) & merged_df['sep_median_domain'].notna()\n",
    "    merged_df.loc[condition, 'sep_median'] = merged_df.loc[condition, 'sep_median_domain']\n",
    "    \n",
    "    # Drop the domain-specific columns used for imputation\n",
    "    merged_df.drop(columns=['sep_median_domain', 'year_domain'], inplace=True)\n",
    "\n",
    "    # Filter the dataframe to keep only the suburbs that appear 9 or more times\n",
    "    suburb_counts = merged_df['suburb'].value_counts()\n",
    "    suburbs_to_keep = suburb_counts[suburb_counts >= 9].index\n",
    "    merged_df = merged_df[merged_df['suburb'].isin(suburbs_to_keep)]\n",
    "    \n",
    "    # Drop the sep_median column from the domain DataFrame\n",
    "    domain_df = domain_df.drop(columns=['year', 'sep_median', 'num_properties'], errors='ignore')\n",
    "    \n",
    "    return merged_df, domain_df\n",
    "\n",
    "# Apply the function to each dataset \n",
    "one_bed_flat, domain_one_bed_flat = impute_sep_2024_rental_data(one_bed_flat, domain_one_bed_flat)\n",
    "two_bed_flat, domain_two_bed_flat = impute_sep_2024_rental_data(two_bed_flat, domain_two_bed_flat)\n",
    "three_bed_flat, domain_three_bed_flat = impute_sep_2024_rental_data(three_bed_flat, domain_three_bed_flat)\n",
    "two_bed_house, domain_two_bed_house = impute_sep_2024_rental_data(two_bed_house, domain_two_bed_house)\n",
    "three_bed_house, domain_three_bed_house = impute_sep_2024_rental_data(three_bed_house, domain_three_bed_house)\n",
    "four_bed_house, domain_four_bed_house = impute_sep_2024_rental_data(four_bed_house, domain_four_bed_house)\n",
    "all_properties, domain_all_properties = impute_sep_2024_rental_data(all_properties, domain_all_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one_bed_flat\n",
    "one_bed_flat_merged = pd.merge(one_bed_flat, crimes, on=['suburb', 'year'], how='outer')\n",
    "one_bed_flat_merged = pd.merge(one_bed_flat_merged, income, on=['suburb', 'year'], how='outer')\n",
    "one_bed_flat_merged = pd.merge(one_bed_flat_merged, population, left_on=['suburb', 'year'], right_on=['sa2_name', 'year'], how='outer')\n",
    "one_bed_flat_merged = pd.merge(one_bed_flat_merged, livability_one_bed_flat, on=['suburb', 'year'], how='inner')\n",
    "one_bed_flat_merged = pd.merge(one_bed_flat_merged, education, on='suburb', how='inner')\n",
    "one_bed_flat_merged = pd.merge(one_bed_flat_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "one_bed_flat_merged = pd.merge(one_bed_flat_merged, pt_distances, on='suburb', how='inner')\n",
    "one_bed_flat_merged = pd.merge(one_bed_flat_merged, domain_one_bed_flat, on='suburb', how='inner')\n",
    "\n",
    "# Filter rows to retain only matching suburbs in one_bed_flat and the population dataframe\n",
    "one_bed_flat_merged = one_bed_flat_merged[one_bed_flat_merged['suburb'].isin(population['sa2_name'])]\n",
    "one_bed_flat_merged = one_bed_flat_merged.drop_duplicates()\n",
    "\n",
    "\n",
    "# Merge two_bed_flat\n",
    "two_bed_flat_merged = pd.merge(two_bed_flat, crimes, on=['suburb', 'year'], how='outer')\n",
    "two_bed_flat_merged = pd.merge(two_bed_flat_merged, income, on=['suburb', 'year'], how='outer')\n",
    "two_bed_flat_merged = pd.merge(two_bed_flat_merged, population, left_on=['suburb', 'year'], right_on=['sa2_name', 'year'], how='outer')\n",
    "two_bed_flat_merged = pd.merge(two_bed_flat_merged, livability_two_bed_flat, on=['suburb', 'year'], how='inner')\n",
    "two_bed_flat_merged = pd.merge(two_bed_flat_merged, education, on='suburb', how='inner')\n",
    "two_bed_flat_merged = pd.merge(two_bed_flat_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "two_bed_flat_merged = pd.merge(two_bed_flat_merged, pt_distances, on='suburb', how='inner')\n",
    "two_bed_flat_merged = pd.merge(two_bed_flat_merged, domain_two_bed_flat, on='suburb', how='inner')\n",
    "\n",
    "# Filter rows to retain only matching suburbs in two_bed_flat and the population dataframe\n",
    "two_bed_flat_merged = two_bed_flat_merged[two_bed_flat_merged['suburb'].isin(population['sa2_name'])]\n",
    "two_bed_flat_merged = two_bed_flat_merged.drop_duplicates()\n",
    "\n",
    "\n",
    "# Merge three_bed_flat\n",
    "three_bed_flat_merged = pd.merge(three_bed_flat, crimes, on=['suburb', 'year'], how='outer')\n",
    "three_bed_flat_merged = pd.merge(three_bed_flat_merged, income, on=['suburb', 'year'], how='outer')\n",
    "three_bed_flat_merged = pd.merge(three_bed_flat_merged, population, left_on=['suburb', 'year'], right_on=['sa2_name', 'year'], how='outer')\n",
    "three_bed_flat_merged = pd.merge(three_bed_flat_merged, livability_three_bed_flat, on=['suburb', 'year'], how='inner')\n",
    "three_bed_flat_merged = pd.merge(three_bed_flat_merged, education, on='suburb', how='inner')\n",
    "three_bed_flat_merged = pd.merge(three_bed_flat_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "three_bed_flat_merged = pd.merge(three_bed_flat_merged, pt_distances, on='suburb', how='inner')\n",
    "three_bed_flat_merged = pd.merge(three_bed_flat_merged, domain_three_bed_flat, on='suburb', how='inner')\n",
    "\n",
    "# Filter rows to retain only matching suburbs in three_bed_flat and the population dataframe\n",
    "three_bed_flat_merged = three_bed_flat_merged[three_bed_flat_merged['suburb'].isin(population['sa2_name'])]\n",
    "three_bed_flat_merged = three_bed_flat_merged.drop_duplicates()\n",
    "\n",
    "\n",
    "# Merge two_bed_house\n",
    "two_bed_house_merged = pd.merge(two_bed_house, crimes, on=['suburb', 'year'], how='outer')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, income, on=['suburb', 'year'], how='outer')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, population, left_on=['suburb', 'year'], right_on=['sa2_name', 'year'], how='outer')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, livability_two_bed_house, on=['suburb', 'year'], how='inner')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, education, on='suburb', how='inner')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, pt_distances, on='suburb', how='inner')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, domain_two_bed_house, on='suburb', how='inner')\n",
    "\n",
    "# Filter rows to retain only matching suburbs in two_bed_house and the population dataframe\n",
    "two_bed_house_merged = two_bed_house_merged[two_bed_house_merged['suburb'].isin(population['sa2_name'])]\n",
    "two_bed_house_merged = two_bed_house_merged.drop_duplicates()\n",
    "\n",
    "\n",
    "# Merge three_bed_house\n",
    "three_bed_house_merged = pd.merge(three_bed_house, crimes, on=['suburb', 'year'], how='outer')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, income, on=['suburb', 'year'], how='outer')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, population, left_on=['suburb', 'year'], right_on=['sa2_name', 'year'], how='outer')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, livability_three_bed_house, on=['suburb', 'year'], how='inner')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, education, on='suburb', how='inner')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, pt_distances, on='suburb', how='inner')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, domain_three_bed_house, on='suburb', how='inner')\n",
    "\n",
    "# Filter rows to retain only matching suburbs in three_bed_house and the population dataframe\n",
    "three_bed_house_merged = three_bed_house_merged[three_bed_house_merged['suburb'].isin(population['sa2_name'])]\n",
    "three_bed_house_merged = three_bed_house_merged.drop_duplicates()\n",
    "\n",
    "\n",
    "# Merge four_bed_house\n",
    "four_bed_house_merged = pd.merge(four_bed_house, crimes, on=['suburb', 'year'], how='outer')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, income, on=['suburb', 'year'], how='outer')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, population, left_on=['suburb', 'year'], right_on=['sa2_name', 'year'], how='outer')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, livability_four_bed_house, on=['suburb', 'year'], how='inner')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, education, on='suburb', how='inner')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, pt_distances, on='suburb', how='inner')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, domain_four_bed_house, on='suburb', how='inner')\n",
    "\n",
    "# Filter rows to retain only matching suburbs in four_bed_house and the population dataframe\n",
    "four_bed_house_merged = four_bed_house_merged[four_bed_house_merged['suburb'].isin(population['sa2_name'])]\n",
    "four_bed_house_merged =four_bed_house_merged.drop_duplicates()\n",
    "\n",
    "# Merge all_properties\n",
    "all_properties_merged = pd.merge(all_properties, crimes, on=['suburb', 'year'], how='outer')\n",
    "all_properties_merged = pd.merge(all_properties_merged, income, on=['suburb', 'year'], how='outer')\n",
    "all_properties_merged = pd.merge(all_properties_merged, population, left_on=['suburb', 'year'], right_on=['sa2_name', 'year'], how='outer')\n",
    "all_properties_merged = pd.merge(all_properties_merged, livability_all_properties, on=['suburb', 'year'], how='inner')\n",
    "all_properties_merged = pd.merge(all_properties_merged, education, on='suburb', how='inner')\n",
    "all_properties_merged = pd.merge(all_properties_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "all_properties_merged = pd.merge(all_properties_merged, pt_distances, on='suburb', how='inner')\n",
    "all_properties_merged = pd.merge(all_properties_merged, domain_all_properties, on='suburb', how='inner')\n",
    "\n",
    "# Filter rows to retain only matching suburbs in all_properties and the population dataframe\n",
    "all_properties_merged = all_properties_merged[all_properties_merged['suburb'].isin(population['sa2_name'])]\n",
    "all_properties_merged = all_properties_merged.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2364, 88)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all other suburb column names. Only keep the first suburb column \n",
    "def clean_suburb_cols(df):\n",
    "    \"\"\"\n",
    "    This function removes all duplicates of the suburb column name \n",
    "    from the merged dataframes. The duplicate suburb column name \n",
    "    could be 'Unnamed', 'sa2_name' or 'gazetted_locality'.\n",
    "    \"\"\"\n",
    "    df = df.loc[:, ~df.columns.str.contains('Unnamed')]  # removes the duplicate 'suburb' column\n",
    "    columns_to_drop = ['sa2_name', 'gazetted_locality']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Clean the column names\n",
    "one_bed_flat_merged = clean_suburb_cols(one_bed_flat_merged)\n",
    "two_bed_flat_merged = clean_suburb_cols(two_bed_flat_merged)\n",
    "three_bed_flat_merged = clean_suburb_cols(three_bed_flat_merged)\n",
    "two_bed_house_merged = clean_suburb_cols(two_bed_house_merged)\n",
    "three_bed_house_merged = clean_suburb_cols(three_bed_house_merged)\n",
    "four_bed_house_merged = clean_suburb_cols(four_bed_house_merged)\n",
    "all_properties_merged = clean_suburb_cols(all_properties_merged)\n",
    "all_properties_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2364, 88)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_nan_before_2025(df, median_columns):\n",
    "    \"\"\"\n",
    "    This function removes all suburbs that has missing median rent values in the data \n",
    "    from the years before 2025. This excludes suburbs which would have had NaN values\n",
    "    in our training set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Drop rows where year is less than 2025 and NaN values exist in any of the median columns\n",
    "    return df[~((df['year'] < 2025) & (df[median_columns].isnull().any(axis=1)))]\n",
    "\n",
    "# Define the median columns to check\n",
    "median_columns = ['dec_median', 'jun_median', 'mar_median', 'sep_median']\n",
    "\n",
    "# Call the function for each dataframe and reassign the cleaned data\n",
    "one_bed_flat_merged = remove_nan_before_2025(one_bed_flat_merged, median_columns)\n",
    "two_bed_flat_merged = remove_nan_before_2025(two_bed_flat_merged, median_columns)\n",
    "three_bed_flat_merged = remove_nan_before_2025(three_bed_flat_merged, median_columns)\n",
    "two_bed_house_merged = remove_nan_before_2025(two_bed_house_merged, median_columns)\n",
    "three_bed_house_merged = remove_nan_before_2025(three_bed_house_merged, median_columns)\n",
    "four_bed_house_merged = remove_nan_before_2025(four_bed_house_merged, median_columns)\n",
    "all_properties_merged = remove_nan_before_2025(all_properties_merged, median_columns)\n",
    "all_properties_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save All Properties Dataframe for Visualisation Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_merged_dataframes():\n",
    "    \"\"\"\n",
    "    This function saves all merged dataframes to the defined path.\n",
    "    \"\"\"\n",
    "    # Define the base path\n",
    "    base_path = '../data/curated/merged_feature_set'\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "\n",
    "    # Save each dataframe to a CSV file\n",
    "    one_bed_flat_merged.to_csv(os.path.join(base_path, 'one_bed_flat_merged.csv'), index=False)\n",
    "    two_bed_flat_merged.to_csv(os.path.join(base_path, 'two_bed_flat_merged.csv'), index=False)\n",
    "    three_bed_flat_merged.to_csv(os.path.join(base_path, 'three_bed_flat_merged.csv'), index=False)\n",
    "    two_bed_house_merged.to_csv(os.path.join(base_path, 'two_bed_house_merged.csv'), index=False)\n",
    "    three_bed_house_merged.to_csv(os.path.join(base_path, 'three_bed_house_merged.csv'), index=False)\n",
    "    four_bed_house_merged.to_csv(os.path.join(base_path, 'four_bed_house_merged.csv'), index=False)\n",
    "    all_properties_merged.to_csv(os.path.join(base_path, 'all_properties_merged.csv'), index=False)\n",
    "\n",
    "# Call the function\n",
    "save_merged_dataframes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
