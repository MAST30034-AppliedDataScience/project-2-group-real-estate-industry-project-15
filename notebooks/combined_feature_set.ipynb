{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rental History Data\n",
    "one_bed_flat = pd.read_csv('../data/raw/rental_history/one_bed_flat.csv')\n",
    "two_bed_flat = pd.read_csv('../data/raw/rental_history/two_bed_flat.csv')\n",
    "three_bed_flat = pd.read_csv('../data/raw/rental_history/three_bed_flat.csv')\n",
    "two_bed_house = pd.read_csv('../data/raw/rental_history/two_bed_house.csv')\n",
    "three_bed_house = pd.read_csv('../data/raw/rental_history/three_bed_house.csv')\n",
    "four_bed_house = pd.read_csv('../data/raw/rental_history/four_bed_house.csv')\n",
    "all_properties = pd.read_csv('../data/raw/rental_history/all_properties.csv')\n",
    "\n",
    "# Domain Rental Data\n",
    "domain_one_bed_flat = pd.read_csv('../data/curated/domain_one_bed_flat_rent.csv')\n",
    "domain_two_bed_flat = pd.read_csv('../data/curated/domain_two_bed_flat_rent.csv')\n",
    "domain_three_bed_flat = pd.read_csv('../data/curated/domain_three_bed_flat_rent.csv')\n",
    "domain_two_bed_house = pd.read_csv('../data/curated/domain_two_bed_house_rent.csv')\n",
    "domain_three_bed_house = pd.read_csv('../data/curated/domain_three_bed_house_rent.csv')\n",
    "domain_four_bed_house = pd.read_csv('../data/curated/domain_four_bed_house.csv')\n",
    "domain_all_properties = pd.read_csv('../data/curated/domain_all_properties_rent.csv')\n",
    "\n",
    "# Other engineered feature sets \n",
    "crimes = pd.read_csv('../data/curated/crimes.csv')\n",
    "population = pd.read_csv('../data/curated/final_population.csv')\n",
    "education = pd.read_csv('../data/curated/education_df.csv')\n",
    "urban_landmarks = pd.read_csv('../data/raw/urban_landmarks_features.csv')\n",
    "pt_distances = pd.read_csv('../data/curated/suburb_transport_distances.csv')\n",
    "income_2016 = pd.read_csv('../data/curated/income_2016.csv')\n",
    "income_2021 = pd.read_csv('../data/curated/income_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one_bed_flat\n",
    "one_bed_merged = pd.merge(one_bed_flat, domain_one_bed_flat, on='suburb', how='inner')\n",
    "one_bed_merged = pd.merge(one_bed_merged, crimes, on='suburb', how='inner')\n",
    "one_bed_merged = pd.merge(one_bed_merged, population, left_on='suburb', right_on='sa2_name', how='inner')\n",
    "one_bed_merged = pd.merge(one_bed_merged, education, on='suburb', how='inner')\n",
    "one_bed_merged = pd.merge(one_bed_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "one_bed_merged = pd.merge(one_bed_merged, pt_distances, on='suburb', how='inner')\n",
    "one_bed_merged = pd.merge(one_bed_merged, income_2016, on='suburb', how='inner')\n",
    "one_bed_merged = pd.merge(one_bed_merged, income_2021, on='suburb', how='inner')\n",
    "\n",
    "# Merge two_bed_flat\n",
    "two_bed_merged = pd.merge(two_bed_flat, domain_two_bed_flat, on='suburb', how='inner')\n",
    "two_bed_merged = pd.merge(two_bed_merged, crimes, on='suburb', how='inner')\n",
    "two_bed_merged = pd.merge(two_bed_merged, population, left_on='suburb', right_on='sa2_name', how='inner')\n",
    "two_bed_merged = pd.merge(two_bed_merged, education, on='suburb', how='inner')\n",
    "two_bed_merged = pd.merge(two_bed_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "two_bed_merged = pd.merge(two_bed_merged, pt_distances, on='suburb', how='inner')\n",
    "two_bed_merged = pd.merge(two_bed_merged, income_2016, on='suburb', how='inner')\n",
    "two_bed_merged = pd.merge(two_bed_merged, income_2021, on='suburb', how='inner')\n",
    "\n",
    "# Merge three_bed_flat\n",
    "three_bed_merged = pd.merge(three_bed_flat, domain_three_bed_flat, on='suburb', how='inner')\n",
    "three_bed_merged = pd.merge(three_bed_merged, crimes, on='suburb', how='inner')\n",
    "three_bed_merged = pd.merge(three_bed_merged, population, left_on='suburb', right_on='sa2_name', how='inner')\n",
    "three_bed_merged = pd.merge(three_bed_merged, education, on='suburb', how='inner')\n",
    "three_bed_merged = pd.merge(three_bed_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "three_bed_merged = pd.merge(three_bed_merged, pt_distances, on='suburb', how='inner')\n",
    "three_bed_merged = pd.merge(three_bed_merged, income_2016, on='suburb', how='inner')\n",
    "three_bed_merged = pd.merge(three_bed_merged, income_2021, on='suburb', how='inner')\n",
    "\n",
    "# Merge two_bed_house\n",
    "two_bed_house_merged = pd.merge(two_bed_house, domain_two_bed_house, on='suburb', how='inner')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, crimes, on='suburb', how='inner')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, population, left_on='suburb', right_on='sa2_name', how='inner')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, education, on='suburb', how='inner')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, pt_distances, on='suburb', how='inner')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, income_2016, on='suburb', how='inner')\n",
    "two_bed_house_merged = pd.merge(two_bed_house_merged, income_2021, on='suburb', how='inner')\n",
    "\n",
    "# Merge three_bed_house\n",
    "three_bed_house_merged = pd.merge(three_bed_house, domain_three_bed_house, on='suburb', how='inner')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, crimes, on='suburb', how='inner')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, population, left_on='suburb', right_on='sa2_name', how='inner')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, education, on='suburb', how='inner')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "three_bed_house_merged = pd.merge(three_bed_house_merged, pt_distances, on='suburb', how='inner')\n",
    "three_bed_house_merged = pd.merge(two_bed_house_merged, income_2016, on='suburb', how='inner')\n",
    "three_bed_house_merged = pd.merge(two_bed_house_merged, income_2021, on='suburb', how='inner')\n",
    "\n",
    "# Merge four_bed_house\n",
    "four_bed_house_merged = pd.merge(four_bed_house, domain_four_bed_house, on='suburb', how='inner')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, crimes, on='suburb', how='inner')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, population, left_on='suburb', right_on='sa2_name', how='inner')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, education, on='suburb', how='inner')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, pt_distances, on='suburb', how='inner')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, income_2016, on='suburb', how='inner')\n",
    "four_bed_house_merged = pd.merge(four_bed_house_merged, income_2021, on='suburb', how='inner')\n",
    "\n",
    "# Merge all_properties\n",
    "all_properties_merged = pd.merge(all_properties, domain_all_properties, on='suburb', how='inner')\n",
    "all_properties_merged = pd.merge(all_properties_merged, crimes, on='suburb', how='inner')\n",
    "all_properties_merged = pd.merge(all_properties_merged, population, left_on='suburb', right_on='sa2_name', how='inner')\n",
    "all_properties_merged = pd.merge(all_properties_merged, education, on='suburb', how='inner')\n",
    "all_properties_merged = pd.merge(all_properties_merged, urban_landmarks, left_on='suburb', right_on='gazetted_locality', how='inner')\n",
    "all_properties_merged = pd.merge(all_properties_merged, pt_distances, on='suburb', how='inner')\n",
    "all_properties_merged = pd.merge(all_properties_merged, income_2016, on='suburb', how='inner')\n",
    "all_properties_merged = pd.merge(all_properties_merged, income_2021, on='suburb', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all other suburb column names. Only keep the first suburb column \n",
    "def clean_merged_df(df):\n",
    "    \n",
    "    df = df.loc[:, ~df.columns.str.contains('Unnamed')]  # removes the duplicate 'suburb' column\n",
    "    columns_to_drop = ['sa2_name', 'gazetted_locality']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Clean the column names\n",
    "one_bed_merged = clean_merged_df(one_bed_merged)\n",
    "two_bed_merged = clean_merged_df(two_bed_merged)\n",
    "three_bed_merged = clean_merged_df(three_bed_merged)\n",
    "two_bed_house_merged = clean_merged_df(two_bed_house_merged,)\n",
    "three_bed_house_merged = clean_merged_df(three_bed_house_merged)\n",
    "four_bed_house_merged = clean_merged_df(four_bed_house_merged)\n",
    "all_properties_merged = clean_merged_df(all_properties_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_sets(df, is_crime_data=False):\n",
    "    \"\"\"\n",
    "    Input the dataframe. The train sets include the data from the year of 2016-2021 and \n",
    "    the test sets include years from 2022-2024. The label sets (y) should only include the \n",
    "    median house prices for each month and year, whereas the predictor variables (X) should \n",
    "    include any engineered features correspondeiing to the years of the train and test sets \n",
    "    whilst also including the general features we created relevant to each suburb. Return\n",
    "    the following dataframes: X_train, X_test, y_train, y_test.\n",
    "    \"\"\"\n",
    "\n",
    "    # Train set columns = 2016-2021, Test set columns = 2022-2024\n",
    "    train_years = [str(year) for year in range(2016, 2022)]\n",
    "    test_years = [str(year) for year in range(2022, 2025)]\n",
    "\n",
    "    # Filter for the respective columns for the training and test set \n",
    "    train_columns = [col for col in df.columns if any(year in col for year in train_years)]\n",
    "    test_columns = [col for col in df.columns if any(year in col for year in test_years)]\n",
    "\n",
    "     # Identify columns that do not contain any year and add them to the train and test sets \n",
    "    non_year_columns = [col for col in df.columns if not any(str(year) in col for year in range(2016, 2025))]\n",
    "\n",
    "     # Exclude the 'suburb' column if it exists\n",
    "    if 'suburb' in non_year_columns:\n",
    "        non_year_columns.remove('suburb')\n",
    "        \n",
    "    train_columns.extend(non_year_columns)\n",
    "    test_columns.extend(non_year_columns)\n",
    "\n",
    "    # Extract features and target columns\n",
    "    X_train = df[[col for col in train_columns if '_median' not in col]]\n",
    "    y_train = df[[col for col in train_columns if '_median' in col]]\n",
    "\n",
    "    X_test = df[[col for col in test_columns if '_median' not in col]]\n",
    "    y_test = df[[col for col in test_columns if '_median' in col]]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Create training and test sets \n",
    "X_train_one_bed, X_test_one_bed, y_train_one_bed, y_test_one_bed = train_test_sets(one_bed_merged)\n",
    "X_train_two_bed, X_test_two_bed, y_train_two_bed, y_test_two_bed = train_test_sets(two_bed_merged)\n",
    "X_train_three_bed, X_test_three_bed, y_train_three_bed, y_test_three_bed = train_test_sets(three_bed_merged)\n",
    "X_train_two_bed_house, X_test_two_bed_house, y_train_two_bed_house, y_test_two_bed_house = train_test_sets(two_bed_house_merged)\n",
    "X_train_three_bed_house, X_test_three_bed_house, y_train_three_bed_house, y_test_three_bed_house = train_test_sets(three_bed_house_merged)\n",
    "X_train_four_bed_house, X_test_four_bed_house, y_train_four_bed_house, y_test_four_bed_house = train_test_sets(four_bed_house_merged)\n",
    "X_train_all_properties, X_test_all_properties, y_train_all_properties, y_test_all_properties = train_test_sets(all_properties_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['personal_income_count_2020', 'personal_total_income_millions_2020',\n",
       "       'median_personal_total_income_2020', 'mean_personal_total_income_2020',\n",
       "       'gini_coef_2020', 'hi_1_149_tot_2016', 'hi_150_299_tot_2016',\n",
       "       'hi_300_399_tot_2016', 'hi_400_499_tot_2016', 'hi_500_649_tot_2016',\n",
       "       ...\n",
       "       'distance_to_hotel', 'distance_to_kindergarten', 'distance_to_library',\n",
       "       'distance_to_mall', 'distance_to_park', 'distance_to_police',\n",
       "       'distance_to_restaurant', 'distance_to_supermarket',\n",
       "       'nearest_transport_avg_distance', 'distance_to_cbd'],\n",
       "      dtype='object', length=109)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_one_bed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values and their counts:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "missing_values = X_test_one_bed.isnull().sum()\n",
    "\n",
    "# Filter columns that have missing values\n",
    "columns_with_missing = missing_values[missing_values > 0]\n",
    "\n",
    "# Display the columns with missing values and their counts\n",
    "print(\"Columns with missing values and their counts:\")\n",
    "print(columns_with_missing)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
