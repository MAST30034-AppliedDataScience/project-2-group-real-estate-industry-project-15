{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE READ: DATA DOWNLOAD\n",
    "\n",
    "### Before running this notebook, please ensure that you have downloaded the files in the `Income Landing Data` folder from our [Google Drive](https://drive.google.com/drive/folders/1JzqWIVPAHOvMeD0X1u3RefYBSj1PehZ0?usp=sharing), saving them to the `data/landing/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Income Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries & Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import regex as re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Household Income \n",
    "income_2016 = pd.read_csv(\"../../data/landing/2016Census_G29_VIC_SA2.csv\")\n",
    "income_2021 = pd.read_csv(\"../../data/landing/2021Census_G33_VIC_SA2.csv\")\n",
    "\n",
    "# SA2 Codes and Suburb Names \n",
    "sa2_2016 = pd.read_csv(\"../../data/landing/SA2_codes_2016.csv\")\n",
    "sa2_2021 = pd.read_excel(\"../../data/landing/SA2_codes_2021.xlsx\", sheet_name=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column names lowercase\n",
    "income_2016.columns = income_2016.columns.str.lower()\n",
    "income_2021.columns = income_2021.columns.str.lower()\n",
    "\n",
    "# Make the column names cohesive\n",
    "income_2016 = income_2016.rename(columns={\n",
    "    \"sa2_maincode_2016\": \"sa2_code_2016\"\n",
    "})\n",
    "\n",
    "# Only retrieve the total household income columns \n",
    "income_2016 = income_2016[['sa2_code_2016'] + income_2016.filter(regex='_tot$').columns.tolist()]\n",
    "income_2021 = income_2021[['sa2_code_2021'] + income_2021.filter(regex='_tot$').columns.tolist()]\n",
    "\n",
    "# Drop the last 3 columns as they are not relevant \n",
    "income_2016 = income_2016.iloc[:, :-3]\n",
    "income_2021 = income_2021.iloc[:, :-3]\n",
    "\n",
    "# Drop the second column as it is not relevant \n",
    "income_2016 = income_2016.drop(income_2016.columns[1], axis=1)\n",
    "income_2021 = income_2021.drop(income_2021.columns[1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the SA2 Codes and Suburb Names Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column names lowercase\n",
    "sa2_2016.columns = sa2_2016.columns.str.lower()\n",
    "sa2_2021.columns = sa2_2021.columns.str.lower()\n",
    "\n",
    "# Make all string columns lower case\n",
    "sa2_2016 = sa2_2016.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "sa2_2021 = sa2_2021.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "# Only retrieve the SA2 codes and suburb names \n",
    "sa2_2016 = sa2_2016[[\"sa2_maincode_2016\", \"sa2_name_2016\"]]\n",
    "sa2_2021 = sa2_2021[[\"asgs_structure\", \"census_code_2021\", \"census_name_2021\"]]\n",
    "\n",
    "# For 2021, filter only for SA2 codes and names \n",
    "sa2_2021 = sa2_2021[\n",
    "    (sa2_2021['asgs_structure'] == 'sa2') & \n",
    "    (sa2_2021['census_code_2021'].astype(str).str.startswith('2'))\n",
    "]\n",
    "\n",
    "# Clean the column names and dataframe \n",
    "sa2_2016 = sa2_2016.rename(columns={\n",
    "    \"sa2_maincode_2016\": \"sa2_code_2016\"\n",
    "})\n",
    "\n",
    "sa2_2021 = sa2_2021.rename(columns={\n",
    "    \"census_code_2021\": \"sa2_code_2021\",\n",
    "    \"census_name_2021\": \"sa2_name_2021\"\n",
    "}).drop(columns=[\"asgs_structure\"])\n",
    "\n",
    "# Convert code columns to int64 and name columns to string \n",
    "sa2_2016['sa2_code_2016'] = sa2_2016['sa2_code_2016'].astype('int64')\n",
    "sa2_2016['sa2_name_2016'] = sa2_2016['sa2_name_2016'].astype('str')\n",
    "\n",
    "sa2_2021['sa2_code_2021'] = sa2_2021['sa2_code_2021'].astype('int64')\n",
    "sa2_2021['sa2_name_2021'] = sa2_2021['sa2_name_2021'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map SA2 Codes in the Income Dataset to the Suburb Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge income datasets with sa2 datasets to replace the SA2 code with the SA2 name\n",
    "income_2016 = income_2016.merge(sa2_2016, left_on='sa2_code_2016', right_on='sa2_code_2016', how='inner')\n",
    "income_2016['sa2_code_2016'] = income_2016['sa2_name_2016']  \n",
    "income_2016 = income_2016.drop(['sa2_code_2016'], axis=1)  \n",
    "\n",
    "# Reorder to place sa2_name_2016 as the first column\n",
    "income_2016 = income_2016[['sa2_name_2016'] + [col for col in income_2016.columns if col != 'sa2_name_2016']]\n",
    "\n",
    "# Do the same for 2021 income dataset\n",
    "income_2021 = income_2021.merge(sa2_2021, left_on='sa2_code_2021', right_on='sa2_code_2021', how='inner')\n",
    "income_2021['sa2_code_2021'] = income_2021['sa2_name_2021']  \n",
    "income_2021 = income_2021.drop(['sa2_code_2021'], axis=1)  \n",
    "income_2021 = income_2021[['sa2_name_2021'] + [col for col in income_2021.columns if col != 'sa2_name_2021']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing and Removing Directional Modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directional modifiers and the word 'surrounds' to be removed\n",
    "directional_modifiers = [' - east', ' - west', ' - north', ' - south', ' - central', ' surrounds', ' (north)', ' (south)', ' (east)', ' (west)', ' region']\n",
    "pattern = '|'.join([re.escape(suffix) for suffix in directional_modifiers])\n",
    "\n",
    "income_2016['sa2_name_2016'] = income_2016['sa2_name_2016'].str.replace(pattern, '', regex=True)\n",
    "income_2021['sa2_name_2021'] = income_2021['sa2_name_2021'].str.replace(pattern, '', regex=True)\n",
    "\n",
    "# Split sa2_name where multiple names are separated by hyphens\n",
    "income_2016['sa2_name_2016'] = income_2016['sa2_name_2016'].str.split(' - ')\n",
    "income_2021['sa2_name_2021'] = income_2021['sa2_name_2021'].str.split(' - ')\n",
    "\n",
    "# Explode the lists into separate rows\n",
    "income_2016_exploded = income_2016.explode('sa2_name_2016')\n",
    "income_2016_exploded = income_2016_exploded.reset_index(drop=True)\n",
    "\n",
    "income_2021_exploded = income_2021.explode('sa2_name_2021')\n",
    "income_2021_exploded = income_2021_exploded.reset_index(drop=True)\n",
    "\n",
    "# Remove trailing whitespaces\n",
    "income_2016_exploded['sa2_name_2016'] = income_2016_exploded['sa2_name_2016'].str.rstrip()\n",
    "income_2021_exploded['sa2_name_2021'] = income_2021_exploded['sa2_name_2021'].str.rstrip()\n",
    "\n",
    "# Mapping for the SA2 names to the correct suburbs\n",
    "sa2_name_mapping = {\n",
    "    'ballarat' : 'ballarat central',\n",
    "    'flemington racecourse' : 'flemington',\n",
    "    'southbank wharf' : 'south wharf',\n",
    "    'port melbourne industrial' : 'port melbourne',\n",
    "    'reservoir east' : 'reservoir',\n",
    "    'reservoir west' : 'reservoir',\n",
    "    'research warrandyte' : 'warrandyte',\n",
    "    'essendon airport' : 'essendon',\n",
    "    'gladstone parkmeadows' : 'gladstone park',\n",
    "    'craigieburn west' : 'craigieburn',\n",
    "    'wandin' : 'wandin north',\n",
    "    'pakenham east' : 'pakenham',\n",
    "    'pakenham west' : 'pakenham',\n",
    "    'narre warren west' : 'narre warren',\n",
    "    'berwick east' : 'berwick',\n",
    "    'berwick west' : 'berwick',\n",
    "    'point cook east' : 'point cook',\n",
    "    'point cook west' : 'point cook',\n",
    "    'truganina east' : 'truganina',\n",
    "    'truganina west' : 'truganina',\n",
    "    'melbourne cbd' : 'melbourne'\n",
    "}\n",
    "\n",
    "# Remove the \"(vic.)\" from sa2_name values\n",
    "income_2016_exploded['sa2_name_2016'] = income_2016_exploded['sa2_name_2016'].str.replace(r'\\s*\\(vic\\.\\)', '', regex=True)\n",
    "income_2021_exploded['sa2_name_2021'] = income_2021_exploded['sa2_name_2021'].str.replace(r'\\s*\\(vic\\.\\)', '', regex=True)\n",
    "\n",
    "# Replace some names according with the mapping dictionary defined above\n",
    "income_2016_exploded['sa2_name_2016'] = income_2016_exploded['sa2_name_2016'].replace(sa2_name_mapping)\n",
    "income_2021_exploded['sa2_name_2021'] = income_2021_exploded['sa2_name_2021'].replace(sa2_name_mapping)\n",
    "\n",
    "# Convert counts to integers\n",
    "tot_cols = income_2016.columns[income_2016.columns.str.contains('tot')]\n",
    "\n",
    "income_2016_exploded[tot_cols] = income_2016_exploded[tot_cols].astype('int')\n",
    "income_2021_exploded[tot_cols] = income_2021_exploded[tot_cols].astype('int')\n",
    "\n",
    "# Create the aggregation dictionary\n",
    "aggregation_functions = {col: 'sum' for col in tot_cols}\n",
    "\n",
    "# Group by SA2 names and aggregate\n",
    "income_2016_grouped = income_2016_exploded.groupby('sa2_name_2016').agg(aggregation_functions).reset_index()\n",
    "income_2021_grouped = income_2021_exploded.groupby('sa2_name_2021').agg(aggregation_functions).reset_index()\n",
    "\n",
    "# Rename SA2 name column to be suburb\n",
    "income_2016_grouped = income_2016_grouped.rename(columns={\n",
    "    \"sa2_name_2016\": \"suburb\"\n",
    "})\n",
    "\n",
    "income_2021_grouped = income_2021_grouped.rename(columns={\n",
    "    \"sa2_name_2021\": \"suburb\"\n",
    "})\n",
    "\n",
    "# Save as csv's\n",
    "income_2016_grouped.to_csv('../../data/curated/income_2016.csv', index=False)\n",
    "income_2021_grouped.to_csv('../../data/curated/income_2021.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolations & Extrapolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_2016 = pd.read_csv('../../data/curated/income_2016.csv')\n",
    "income_2021 = pd.read_csv('../../data/curated/income_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the columns are structured similarly\n",
    "df_2016 = income_2016.set_index('suburb')\n",
    "df_2021 = income_2021.set_index('suburb')\n",
    "\n",
    "# Rename columns for merging clarity\n",
    "df_2016.columns = df_2016.columns.str.replace('_2016', '')\n",
    "df_2021.columns = df_2021.columns.str.replace('_2021', '')\n",
    "\n",
    "# Create a combined DataFrame for interpolation and prediction\n",
    "df_combined = pd.concat([df_2016.assign(year=2016), df_2021.assign(year=2021)], axis=0).reset_index()\n",
    "\n",
    "# Find suburbs that have 2021 data\n",
    "suburbs_with_2021 = df_combined[df_combined['year'] == 2021]['suburb']\n",
    "\n",
    "# Filter out rows where the suburb is not in the list of suburbs with 2021 data\n",
    "df_combined = df_combined[df_combined['suburb'].isin(suburbs_with_2021)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_years = np.arange(2016, 2022)\n",
    "\n",
    "# Ensure each suburb has rows for every year (including the missing years)\n",
    "df_complete = (\n",
    "    df_combined\n",
    "    .groupby('suburb')\n",
    "    .apply(lambda group: group.set_index('year').reindex(all_years).ffill().bfill().reset_index())\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "columns_with_tot = [col for col in df_complete.columns if 'tot' in col]\n",
    "\n",
    "# Set the values to NaN for the years 2017 to 2020 for these columns\n",
    "df_complete.loc[df_complete['year'].between(2017, 2020), columns_with_tot] = np.nan\n",
    "\n",
    "# Fill in the missing values for 2017 - 2020\n",
    "df_interpolated = df_complete.groupby('suburb').apply(lambda x: x.interpolate(method='linear')).reset_index(drop=True)\n",
    "\n",
    "# Make them integers since they're counts\n",
    "df_interpolated[columns_with_tot] = df_interpolated[columns_with_tot].astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting Future Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_interpolated.copy()\n",
    "\n",
    "# List of columns to forecast\n",
    "columns_to_forecast = df.columns[2:]  \n",
    "\n",
    "# Forecast years\n",
    "forecast_years = [2022, 2023, 2024, 2025, 2026, 2027]\n",
    "\n",
    "# Create an empty list to store forecasted results\n",
    "forecast_results = []\n",
    "\n",
    "# Iterate over each suburb\n",
    "for suburb in df['suburb'].unique():\n",
    "    \n",
    "    # Filter data for the specific suburb\n",
    "    suburb_data = df[df['suburb'] == suburb].set_index('year')\n",
    "    \n",
    "    # Dictionary to store the forecasted values for each column\n",
    "    suburb_forecast = {'suburb': suburb, 'year': forecast_years}\n",
    "    \n",
    "    for column in columns_to_forecast:\n",
    "        # Extract the time series data for the current column\n",
    "        ts = suburb_data[column]\n",
    "        \n",
    "        # Fit the ARIMA model (p, d, q can be optimized or set manually)\n",
    "        model = ARIMA(ts, order=(1,1,1))\n",
    "        fitted_model = model.fit()\n",
    "        \n",
    "        # Forecast the next 6 years\n",
    "        forecast = fitted_model.forecast(steps=len(forecast_years))\n",
    "        \n",
    "        # Add the forecasted values to the suburb_forecast dictionary\n",
    "        suburb_forecast[column] = forecast.values\n",
    "    \n",
    "    # Append the forecast to the result list\n",
    "    forecast_results.append(pd.DataFrame(suburb_forecast))\n",
    "\n",
    "# Concatenate all forecast results into a single DataFrame\n",
    "forecast_df = pd.concat(forecast_results).reset_index(drop=True)\n",
    "\n",
    "# Concatenate df_interpolated and forecast_df along the row axis (axis=0)\n",
    "df_combined = pd.concat([df_interpolated, forecast_df], axis=0)\n",
    "\n",
    "# Sort by suburb and year to maintain chronological order\n",
    "df_combined = df_combined.sort_values(by=['suburb', 'year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the numeric columns\n",
    "numeric_columns = df_combined.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Replace negative values with zero only in the numeric columns\n",
    "df_combined[numeric_columns] = df_combined[numeric_columns].applymap(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "# Replace numbers to integers\n",
    "df_combined[numeric_columns] = df_combined[numeric_columns].applymap(lambda x: round(max(0, x)))\n",
    "\n",
    "# Save as csv\n",
    "df_combined.to_csv('../../data/curated/income_forecasted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
