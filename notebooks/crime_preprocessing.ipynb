{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/09/10 15:06:16 WARN Utils: Your hostname, Mok resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/09/10 15:06:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/10 15:06:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.executor.memory\", \"5g\")\n",
    "    .config(\"spark.driver.memory\", \"5g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_parquet(name, sdf):\n",
    "    '''Input: take a spark dataframe, and a desired file name\n",
    "\n",
    "    A staging folder is created as creating a parquet creates meta data files which are unneeded\n",
    "    for analysis. Relevent parquet files are then moved into the curated folder\n",
    "    \n",
    "    Output: save the new spark data frame into the curated folder ready for analysis'''\n",
    "    \n",
    "    #now we want to move this file into the curated data\n",
    "    import shutil\n",
    "    import os\n",
    "    \n",
    "    folder_path = \"../data/staging\"\n",
    "\n",
    "    # Create the folder, including any intermediate directories\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created successfully!\")\n",
    "    else:\n",
    "        None\n",
    "\n",
    "\n",
    "\n",
    "    sdf.coalesce(1)\\\n",
    "        .write\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .parquet(f'../data/staging/{name}')\n",
    "\n",
    "\n",
    "\n",
    "    starting_directory = '../data/staging/'\n",
    "    output_directory = \"../data/raw/\"\n",
    "\n",
    "    input_directory = os.path.join(starting_directory, name)\n",
    "\n",
    "    for file in os.listdir(input_directory):\n",
    "        if file.endswith(\".parquet\"):\n",
    "            \n",
    "            #rename the file first since currently they have a part-00000 name\n",
    "            part_file_path = os.path.join(input_directory, file)\n",
    "            new_file_path = os.path.join(input_directory, name)\n",
    "            os.rename(part_file_path, new_file_path)\n",
    "                \n",
    "            #move the file into the curated folder for models\n",
    "            source_file_path = os.path.join(input_directory, name)\n",
    "            destination_file_path = os.path.join(output_directory, name)\n",
    "        \n",
    "            shutil.move(source_file_path, destination_file_path)\n",
    "            shutil.rmtree(folder_path)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "crime_raw_sdf = spark.read.parquet('../data/landing/crime.parquet')\n",
    "\n",
    "# we want to remove the subdivisions and LGAS as these are not relevent features \n",
    "offence_division_raw = crime_raw_sdf.drop(\"Offence Subdivision\", \"Offence Subgroup\", \"Year ending\", \"Local Government Area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save this file as a parquet in the raw folder\n",
    "save_df_to_parquet(\"offence_division_raw.parquet\", offence_division_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+--------------------+-------------------+\n",
      "|Year|Suburb/Town Name|    Offence Division|total_offence_count|\n",
      "+----+----------------+--------------------+-------------------+\n",
      "|2023|     Bakery Hill|E Justice procedu...|                  6|\n",
      "|2023|    Lake Gardens|A Crimes against ...|                 12|\n",
      "|2023| Trafalgar South|B Property and de...|                  3|\n",
      "|2023|      Cheltenham|     C Drug offences|                 81|\n",
      "|2023|  Echuca Village|A Crimes against ...|                  5|\n",
      "|2023|           Patho|D Public order an...|                  4|\n",
      "|2023|     Maryborough|A Crimes against ...|                221|\n",
      "|2023|         Warrion|B Property and de...|                  2|\n",
      "|2023|       Ellaswood|E Justice procedu...|                  3|\n",
      "|2023|     Leitchville|D Public order an...|                  8|\n",
      "|2023|      Lake Mundi|D Public order an...|                 11|\n",
      "|2023|      Lethbridge|E Justice procedu...|                  8|\n",
      "|2023|    Golden Gully|E Justice procedu...|                  1|\n",
      "|2023|            Musk|B Property and de...|                  2|\n",
      "|2023|         Rainbow|D Public order an...|                  1|\n",
      "|2023|   Campbellfield|E Justice procedu...|                 67|\n",
      "|2023|       Moorabbin|    F Other offences|                  2|\n",
      "|2023|      Hernes Oak|     C Drug offences|                  1|\n",
      "|2023|      Wedderburn|A Crimes against ...|                 22|\n",
      "|2023|        Merrijig|B Property and de...|                 10|\n",
      "+----+----------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crime_raw_sdf = spark.read.parquet('../data/raw/offence_division_raw.parquet')\n",
    "\n",
    "crime_raw_sdf.createOrReplaceTempView(\"offence_data\")\n",
    "\n",
    "# SQL query to group by 'Year', 'Suburb/Town Name', and 'Offence Division' and sum 'Offence Count'\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        Year,\n",
    "        `Suburb/Town Name`,\n",
    "        `Offence Division`,\n",
    "        SUM(`Offence Count`) AS total_offence_count\n",
    "    FROM offence_data\n",
    "    GROUP BY Year, `Suburb/Town Name`, `Offence Division`\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "result_df = spark.sql(query)\n",
    "\n",
    "# Show the result\n",
    "result_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+--------------------+-------------------+-----------------------+-------------------+\n",
      "|Year|Suburb/Town Name|    Offence Division|total_offence_count|prev_year_offence_count|  percentage_change|\n",
      "+----+----------------+--------------------+-------------------+-----------------------+-------------------+\n",
      "|2018|        Abbeyard|A Crimes against ...|                  2|                   NULL|               NULL|\n",
      "|2016|        Abbeyard|B Property and de...|                  1|                   NULL|               NULL|\n",
      "|2019|        Abbeyard|B Property and de...|                  1|                      1|                0.0|\n",
      "|2021|        Abbeyard|B Property and de...|                  1|                      1|                0.0|\n",
      "|2014|        Abbeyard|D Public order an...|                  2|                   NULL|               NULL|\n",
      "|2014|        Abbeyard|    F Other offences|                  1|                   NULL|               NULL|\n",
      "|2015|        Abbeyard|    F Other offences|                  1|                      1|                0.0|\n",
      "|2014|      Abbotsford|A Crimes against ...|                 65|                   NULL|               NULL|\n",
      "|2015|      Abbotsford|A Crimes against ...|                 89|                     65|  36.92307692307693|\n",
      "|2016|      Abbotsford|A Crimes against ...|                107|                     89| 20.224719101123593|\n",
      "|2017|      Abbotsford|A Crimes against ...|                138|                    107| 28.971962616822427|\n",
      "|2018|      Abbotsford|A Crimes against ...|                100|                    138|-27.536231884057973|\n",
      "|2019|      Abbotsford|A Crimes against ...|                175|                    100|               75.0|\n",
      "|2020|      Abbotsford|A Crimes against ...|                145|                    175|-17.142857142857142|\n",
      "|2021|      Abbotsford|A Crimes against ...|                174|                    145|               20.0|\n",
      "|2022|      Abbotsford|A Crimes against ...|                180|                    174| 3.4482758620689653|\n",
      "|2023|      Abbotsford|A Crimes against ...|                147|                    180|-18.333333333333332|\n",
      "|2014|      Abbotsford|B Property and de...|                788|                   NULL|               NULL|\n",
      "|2015|      Abbotsford|B Property and de...|               1152|                    788| 46.192893401015226|\n",
      "|2016|      Abbotsford|B Property and de...|               1065|                   1152| -7.552083333333333|\n",
      "+----+----------------+--------------------+-------------------+-----------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import lag, col\n",
    "\n",
    "# Step 1: Assuming your DataFrame is already grouped by year, Suburb/Town Name, and Offence Division.\n",
    "# Use the result DataFrame that already has total_offence_count.\n",
    "# For this example, let’s call the DataFrame `df_grouped`\n",
    "\n",
    "# Step 2: Create a window specification that partitions by 'Suburb/Town Name' and 'Offence Division' and orders by 'Year'\n",
    "window_spec = Window.partitionBy('Suburb/Town Name', 'Offence Division').orderBy('Year')\n",
    "\n",
    "# Step 3: Use the lag function to get the previous year's total offence count\n",
    "df_with_prev_year = result_df.withColumn(\n",
    "    'prev_year_offence_count',\n",
    "    lag('total_offence_count').over(window_spec)\n",
    ")\n",
    "\n",
    "# Step 4: Calculate the percentage change\n",
    "df_with_percentage_change = df_with_prev_year.withColumn(\n",
    "    'percentage_change',\n",
    "    ((col('total_offence_count') - col('prev_year_offence_count')) / col('prev_year_offence_count')) * 100\n",
    ")\n",
    "\n",
    "# Step 5: Show the result\n",
    "df_with_percentage_change.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77258"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_percentage_change.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
