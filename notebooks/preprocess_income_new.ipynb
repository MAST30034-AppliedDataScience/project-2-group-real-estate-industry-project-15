{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Income Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries & Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to make script to scrape correspondence file\n",
    "# https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/correspondences/CG_SA2_2016_SA2_2021.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Household Income \n",
    "income_2016 = pd.read_csv(\"../data/landing/2016Census_G29_VIC_SA2.csv\")\n",
    "income_2021 = pd.read_csv(\"../data/landing/2021Census_G33_VIC_SA2.csv\")\n",
    "\n",
    "# SA2 Codes and Suburb Names \n",
    "sa2_2016 = pd.read_csv(\"../data/landing/SA2_codes_2016.csv\")\n",
    "sa2_2021 = pd.read_excel(\"../data/landing/SA2_codes_2021.xlsx\", sheet_name=0)\n",
    "\n",
    "# correspondence = pd.read_csv('../data/landing/CG_SA2_2016_SA2_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Schema and Null Values \n",
    "# print(income_2016.info())\n",
    "# print(income_2021.info())\n",
    "\n",
    "# Make column names lowercase\n",
    "income_2016.columns = income_2016.columns.str.lower()\n",
    "income_2021.columns = income_2021.columns.str.lower()\n",
    "\n",
    "# Make the column names cohesive\n",
    "income_2016 = income_2016.rename(columns={\n",
    "    \"sa2_maincode_2016\": \"sa2_code_2016\"\n",
    "})\n",
    "\n",
    "# Only retrieve the total household income columns \n",
    "income_2016 = income_2016[['sa2_code_2016'] + income_2016.filter(regex='_tot$').columns.tolist()]\n",
    "income_2021 = income_2021[['sa2_code_2021'] + income_2021.filter(regex='_tot$').columns.tolist()]\n",
    "\n",
    "# Drop the last 3 columns as they are not relevant \n",
    "income_2016 = income_2016.iloc[:, :-3]\n",
    "income_2021 = income_2021.iloc[:, :-3]\n",
    "\n",
    "# Drop the second column as it is not relevant \n",
    "income_2016 = income_2016.drop(income_2016.columns[1], axis=1)\n",
    "income_2021 = income_2021.drop(income_2021.columns[1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the SA2 Codes and Suburb Names Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column names lowercase\n",
    "sa2_2016.columns = sa2_2016.columns.str.lower()\n",
    "sa2_2021.columns = sa2_2021.columns.str.lower()\n",
    "\n",
    "# Make all string columns lower case\n",
    "sa2_2016 = sa2_2016.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "sa2_2021 = sa2_2021.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "# Only retrieve the SA2 codes and suburb names \n",
    "sa2_2016 = sa2_2016[[\"sa2_maincode_2016\", \"sa2_name_2016\"]]\n",
    "sa2_2021 = sa2_2021[[\"asgs_structure\", \"census_code_2021\", \"census_name_2021\"]]\n",
    "\n",
    "# For 2021, filter only for SA2 codes and names \n",
    "sa2_2021 = sa2_2021[\n",
    "    (sa2_2021['asgs_structure'] == 'sa2') & \n",
    "    (sa2_2021['census_code_2021'].astype(str).str.startswith('2'))\n",
    "]\n",
    "\n",
    "# Clean the column names and dataframe \n",
    "sa2_2016 = sa2_2016.rename(columns={\n",
    "    \"sa2_maincode_2016\": \"sa2_code_2016\"\n",
    "})\n",
    "\n",
    "sa2_2021 = sa2_2021.rename(columns={\n",
    "    \"census_code_2021\": \"sa2_code_2021\",\n",
    "    \"census_name_2021\": \"sa2_name_2021\"\n",
    "}).drop(columns=[\"asgs_structure\"])\n",
    "\n",
    "# Exlcude the (vic.) that some rows have in sa2_name \n",
    "sa2_2016['sa2_name_2016'] = sa2_2016['sa2_name_2016'].str.replace(r'\\s*\\(vic\\.\\)', '', regex=True)\n",
    "sa2_2021['sa2_name_2021'] = sa2_2021['sa2_name_2021'].str.replace(r'\\s*\\(vic\\.\\)', '', regex=True)\n",
    "\n",
    "# Check Schema \n",
    "# print(sa2_2016.info())\n",
    "# print(sa2_2021.info())\n",
    "\n",
    "# Convert code columns to int64 and name columns to string \n",
    "sa2_2016['sa2_code_2016'] = sa2_2016['sa2_code_2016'].astype('int64')\n",
    "sa2_2016['sa2_name_2016'] = sa2_2016['sa2_name_2016'].astype('str')\n",
    "\n",
    "sa2_2021['sa2_code_2021'] = sa2_2021['sa2_code_2021'].astype('int64')\n",
    "sa2_2021['sa2_name_2021'] = sa2_2021['sa2_name_2021'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map SA2 Codes in the Income Dataset to the Suburb Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge income datasets with sa2 datasets to replace the SA2 code with the SA2 name\n",
    "income_2016 = income_2016.merge(sa2_2016, left_on='sa2_code_2016', right_on='sa2_code_2016', how='inner')\n",
    "income_2016['sa2_code_2016'] = income_2016['sa2_name_2016']  \n",
    "income_2016 = income_2016.drop(['sa2_code_2016'], axis=1)  \n",
    "\n",
    "# Reorder to place sa2_name_2016 as the first column\n",
    "income_2016 = income_2016[['sa2_name_2016'] + [col for col in income_2016.columns if col != 'sa2_name_2016']]\n",
    "\n",
    "# Do the same for 2021 income dataset\n",
    "income_2021 = income_2021.merge(sa2_2021, left_on='sa2_code_2021', right_on='sa2_code_2021', how='inner')\n",
    "income_2021['sa2_code_2021'] = income_2021['sa2_name_2021']  \n",
    "income_2021 = income_2021.drop(['sa2_code_2021'], axis=1)  \n",
    "\n",
    "income_2021 = income_2021[['sa2_name_2021'] + [col for col in income_2021.columns if col != 'sa2_name_2021']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correspondence\n",
    "\n",
    "This is where I thought of doing the mapping for 2016 sa2 name to 2021 sa2 name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correspondence = pd.read_csv('../data/landing/CG_SA2_2016_SA2_2021.csv')\n",
    "\n",
    "# correspondence['SA2_NAME_2016'] = correspondence['SA2_NAME_2016'].str.lower()\n",
    "# correspondence['SA2_NAME_2021'] = correspondence['SA2_NAME_2021'].str.lower()\n",
    "\n",
    "# correspondence = correspondence[~correspondence['SA2_NAME_2016'].isna() & ~correspondence['SA2_NAME_2021'].isna()]\n",
    "\n",
    "# # Only get data for Victoria\n",
    "# correspondence = correspondence[correspondence['SA2_CODE_2021'].str.startswith('2')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing and Removing Directional Modifiers (Saleha's Preprocessing Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directional modifiers and the word 'surrounds' to be removed\n",
    "directional_modifiers = [' - east', ' - west', ' - north', ' - south', ' - central', ' surrounds', ' (north)', ' (south)', ' (east)', ' (west)', ' region']\n",
    "pattern = '|'.join([re.escape(suffix) for suffix in directional_modifiers])\n",
    "\n",
    "income_2016['sa2_name_2016'] = income_2016['sa2_name_2016'].str.replace(pattern, '', regex=True)\n",
    "income_2021['sa2_name_2021'] = income_2021['sa2_name_2021'].str.replace(pattern, '', regex=True)\n",
    "\n",
    "# Split sa2_name where multiple names are separated by hyphens\n",
    "income_2016['sa2_name_2016'] = income_2016['sa2_name_2016'].str.split(' - ')\n",
    "income_2021['sa2_name_2021'] = income_2021['sa2_name_2021'].str.split(' - ')\n",
    "\n",
    "# Explode the lists into separate rows\n",
    "income_2016_exploded = income_2016.explode('sa2_name_2016')\n",
    "income_2016_exploded = income_2016_exploded.reset_index(drop=True)\n",
    "\n",
    "income_2021_exploded = income_2021.explode('sa2_name_2021')\n",
    "income_2021_exploded = income_2021_exploded.reset_index(drop=True)\n",
    "\n",
    "# Remove trailing whitespaces\n",
    "income_2016_exploded['sa2_name_2016'] = income_2016_exploded['sa2_name_2016'].str.rstrip()\n",
    "income_2021_exploded['sa2_name_2021'] = income_2021_exploded['sa2_name_2021'].str.rstrip()\n",
    "\n",
    "# Mapping for the SA2 names to the correct suburbs\n",
    "sa2_name_mapping = {\n",
    "    'ballarat' : 'ballarat central',\n",
    "    'flemington racecourse' : 'flemington',\n",
    "    'southbank wharf' : 'south wharf',\n",
    "    'port melbourne industrial' : 'port melbourne',\n",
    "    'reservoir east' : 'reservoir',\n",
    "    'reservoir west' : 'reservoir',\n",
    "    'research warrandyte' : 'warrandyte',\n",
    "    'essendon airport' : 'essendon',\n",
    "    'gladstone parkmeadows' : 'gladstone park',\n",
    "    'craigieburn west' : 'craigieburn',\n",
    "    'wandin' : 'wandin north',\n",
    "    'pakenham east' : 'pakenham',\n",
    "    'pakenham west' : 'pakenham',\n",
    "    'narre warren west' : 'narre warren',\n",
    "    'berwick east' : 'berwick',\n",
    "    'berwick west' : 'berwick',\n",
    "    'point cook east' : 'point cook',\n",
    "    'point cook west' : 'point cook',\n",
    "    'truganina east' : 'truganina',\n",
    "    'truganina west' : 'truganina',\n",
    "    'melbourne cbd' : 'melbourne'\n",
    "}\n",
    "\n",
    "# Remove the \"(vic.)\" from sa2_name values\n",
    "income_2016_exploded['sa2_name_2016'] = income_2016_exploded['sa2_name_2016'].str.replace(r'\\s*\\(vic\\.\\)', '', regex=True)\n",
    "income_2016_exploded['sa2_name_2016'] = income_2016_exploded['sa2_name_2016'].replace(sa2_name_mapping)\n",
    "\n",
    "income_2021_exploded['sa2_name_2021'] = income_2021_exploded['sa2_name_2021'].str.replace(r'\\s*\\(vic\\.\\)', '', regex=True)\n",
    "income_2021_exploded['sa2_name_2021'] = income_2021_exploded['sa2_name_2021'].replace(sa2_name_mapping)\n",
    "\n",
    "# Convert counts to integers\n",
    "tot_cols = income_2016.columns[income_2016.columns.str.contains('tot')]\n",
    "\n",
    "income_2016_exploded[tot_cols] = income_2016_exploded[tot_cols].astype('int')\n",
    "income_2021_exploded[tot_cols] = income_2021_exploded[tot_cols].astype('int')\n",
    "\n",
    "# Create the aggregation dictionary\n",
    "aggregation_functions = {col: 'sum' for col in tot_cols}\n",
    "\n",
    "# Apply the groupby and aggregation\n",
    "income_2016_grouped = income_2016_exploded.groupby('sa2_name_2016').agg(aggregation_functions).reset_index()\n",
    "income_2021_grouped = income_2021_exploded.groupby('sa2_name_2021').agg(aggregation_functions).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of suburbs that are in 2016 but not in 2021\n",
    "# list(income_2021_grouped[~income_2021_grouped['suburb'].isin(income_2016_grouped['suburb'])]['suburb'].unique())\n",
    "\n",
    "# Is exactly the same as the 3rd code chunk under Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(478, 17)\n",
      "(520, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suburb</th>\n",
       "      <th>hi_1_149_tot_2021</th>\n",
       "      <th>hi_150_299_tot_2021</th>\n",
       "      <th>hi_300_399_tot_2021</th>\n",
       "      <th>hi_400_499_tot_2021</th>\n",
       "      <th>hi_500_649_tot_2021</th>\n",
       "      <th>hi_650_799_tot_2021</th>\n",
       "      <th>hi_800_999_tot_2021</th>\n",
       "      <th>hi_1000_1249_tot_2021</th>\n",
       "      <th>hi_1250_1499_tot_2021</th>\n",
       "      <th>hi_1500_1749_tot_2021</th>\n",
       "      <th>hi_1750_1999_tot_2021</th>\n",
       "      <th>hi_2000_2499_tot_2021</th>\n",
       "      <th>hi_2500_2999_tot_2021</th>\n",
       "      <th>hi_3000_3499_tot_2021</th>\n",
       "      <th>hi_3500_3999_tot_2021</th>\n",
       "      <th>hi_4000_more_tot_2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abbotsford</td>\n",
       "      <td>28</td>\n",
       "      <td>42</td>\n",
       "      <td>82</td>\n",
       "      <td>119</td>\n",
       "      <td>140</td>\n",
       "      <td>113</td>\n",
       "      <td>164</td>\n",
       "      <td>259</td>\n",
       "      <td>308</td>\n",
       "      <td>253</td>\n",
       "      <td>274</td>\n",
       "      <td>675</td>\n",
       "      <td>295</td>\n",
       "      <td>332</td>\n",
       "      <td>186</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aberfeldie</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>102</td>\n",
       "      <td>250</td>\n",
       "      <td>175</td>\n",
       "      <td>246</td>\n",
       "      <td>271</td>\n",
       "      <td>363</td>\n",
       "      <td>384</td>\n",
       "      <td>342</td>\n",
       "      <td>286</td>\n",
       "      <td>638</td>\n",
       "      <td>397</td>\n",
       "      <td>413</td>\n",
       "      <td>280</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airport west</td>\n",
       "      <td>28</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>215</td>\n",
       "      <td>110</td>\n",
       "      <td>213</td>\n",
       "      <td>178</td>\n",
       "      <td>237</td>\n",
       "      <td>235</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>387</td>\n",
       "      <td>244</td>\n",
       "      <td>242</td>\n",
       "      <td>177</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albert park</td>\n",
       "      <td>47</td>\n",
       "      <td>81</td>\n",
       "      <td>124</td>\n",
       "      <td>221</td>\n",
       "      <td>185</td>\n",
       "      <td>258</td>\n",
       "      <td>273</td>\n",
       "      <td>384</td>\n",
       "      <td>405</td>\n",
       "      <td>382</td>\n",
       "      <td>361</td>\n",
       "      <td>849</td>\n",
       "      <td>321</td>\n",
       "      <td>495</td>\n",
       "      <td>251</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>albion</td>\n",
       "      <td>25</td>\n",
       "      <td>65</td>\n",
       "      <td>119</td>\n",
       "      <td>220</td>\n",
       "      <td>169</td>\n",
       "      <td>178</td>\n",
       "      <td>189</td>\n",
       "      <td>203</td>\n",
       "      <td>235</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>302</td>\n",
       "      <td>184</td>\n",
       "      <td>139</td>\n",
       "      <td>85</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         suburb  hi_1_149_tot_2021  hi_150_299_tot_2021  hi_300_399_tot_2021  \\\n",
       "0    abbotsford                 28                   42                   82   \n",
       "1    aberfeldie                 35                   62                  102   \n",
       "2  airport west                 28                   60                   78   \n",
       "3   albert park                 47                   81                  124   \n",
       "4        albion                 25                   65                  119   \n",
       "\n",
       "   hi_400_499_tot_2021  hi_500_649_tot_2021  hi_650_799_tot_2021  \\\n",
       "0                  119                  140                  113   \n",
       "1                  250                  175                  246   \n",
       "2                  215                  110                  213   \n",
       "3                  221                  185                  258   \n",
       "4                  220                  169                  178   \n",
       "\n",
       "   hi_800_999_tot_2021  hi_1000_1249_tot_2021  hi_1250_1499_tot_2021  \\\n",
       "0                  164                    259                    308   \n",
       "1                  271                    363                    384   \n",
       "2                  178                    237                    235   \n",
       "3                  273                    384                    405   \n",
       "4                  189                    203                    235   \n",
       "\n",
       "   hi_1500_1749_tot_2021  hi_1750_1999_tot_2021  hi_2000_2499_tot_2021  \\\n",
       "0                    253                    274                    675   \n",
       "1                    342                    286                    638   \n",
       "2                    198                    198                    387   \n",
       "3                    382                    361                    849   \n",
       "4                    167                    167                    302   \n",
       "\n",
       "   hi_2500_2999_tot_2021  hi_3000_3499_tot_2021  hi_3500_3999_tot_2021  \\\n",
       "0                    295                    332                    186   \n",
       "1                    397                    413                    280   \n",
       "2                    244                    242                    177   \n",
       "3                    321                    495                    251   \n",
       "4                    184                    139                     85   \n",
       "\n",
       "   hi_4000_more_tot_2021  \n",
       "0                    891  \n",
       "1                   1394  \n",
       "2                    395  \n",
       "3                   1995  \n",
       "4                    195  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename SA2 name column to be suburb\n",
    "income_2016_grouped = income_2016_grouped.rename(columns={\n",
    "    \"sa2_name_2016\": \"suburb\"\n",
    "})\n",
    "\n",
    "income_2021_grouped = income_2021_grouped.rename(columns={\n",
    "    \"sa2_name_2021\": \"suburb\"\n",
    "})\n",
    "\n",
    "# Check dataframes that there are no suburb names with '-'\n",
    "# print(income_2016_grouped[income_2016_grouped['suburb'].str.contains(r'-', na=False)])\n",
    "# print(income_2021_grouped[income_2021_grouped['suburb'].str.contains(r'-', na=False)])\n",
    "\n",
    "# Check both dataframes have the same column names \n",
    "print(income_2016_grouped.columns.equals(income_2021_grouped.columns))\n",
    "\n",
    "# add a tag for the year to each column\n",
    "income_2016_grouped = income_2016_grouped.rename(columns={col: f\"{col}_2016\" if col != 'suburb' else col for col in income_2016_grouped.columns})\n",
    "income_2021_grouped = income_2021_grouped.rename(columns={col: f\"{col}_2021\" if col != 'suburb' else col for col in income_2021_grouped.columns})\n",
    "\n",
    "# Check dataframe dimensions\n",
    "print(income_2016_grouped.shape)\n",
    "print(income_2021_grouped.shape)\n",
    "\n",
    "# View final dataframes \n",
    "income_2021_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Saved!\n"
     ]
    }
   ],
   "source": [
    "income_2016_grouped.to_csv('../data/curated/income_2016.csv', index=False)\n",
    "income_2021_grouped.to_csv('../data/curated/income_2021.csv', index=False)\n",
    "\n",
    "print(\"All Saved!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_2016 = pd.read_csv('../data/curated/income_2016.csv')\n",
    "income_2021 = pd.read_csv('../data/curated/income_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the columns are structured similarly\n",
    "df_2016 = income_2016.set_index('suburb')\n",
    "df_2021 = income_2021.set_index('suburb')\n",
    "\n",
    "# Rename columns for merging clarity\n",
    "df_2016.columns = df_2016.columns.str.replace('_2016', '')\n",
    "df_2021.columns = df_2021.columns.str.replace('_2021', '')\n",
    "\n",
    "# Create a combined DataFrame for interpolation and prediction\n",
    "df_combined = pd.concat([df_2016.assign(year=2016), df_2021.assign(year=2021)], axis=0).reset_index()\n",
    "\n",
    "# Set multi-index with year and suburb\n",
    "#df_combined = df_combined.set_index(['suburb', 'year'])\n",
    "\n",
    "# Find suburbs that have 2021 data\n",
    "suburbs_with_2021 = df_combined[df_combined['year'] == 2021]['suburb']\n",
    "\n",
    "# Filter out rows where the suburb is not in the list of suburbs with 2021 data\n",
    "df_combined = df_combined[df_combined['suburb'].isin(suburbs_with_2021)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "all_years = np.arange(2016, 2022)\n",
    "\n",
    "# Ensure each suburb has rows for every year (including the missing years)\n",
    "df_complete = (\n",
    "    df_combined\n",
    "    .groupby('suburb')\n",
    "    .apply(lambda group: group.set_index('year').reindex(all_years).ffill().bfill().reset_index())\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "columns_with_tot = [col for col in df_complete.columns if 'tot' in col]\n",
    "\n",
    "# Set the values to NaN for the years 2017 to 2020 for these columns\n",
    "df_complete.loc[df_complete['year'].between(2017, 2020), columns_with_tot] = np.nan\n",
    "\n",
    "# df_complete.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the missing values for 2017 - 2020\n",
    "df_interpolated = df_complete.groupby('suburb').apply(lambda x: x.interpolate(method='linear')).reset_index(drop=True)\n",
    "\n",
    "# Make them integers since they're counts\n",
    "df_interpolated[columns_with_tot] = df_interpolated[columns_with_tot].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "      <th>hi_1_149_tot</th>\n",
       "      <th>hi_150_299_tot</th>\n",
       "      <th>hi_300_399_tot</th>\n",
       "      <th>hi_400_499_tot</th>\n",
       "      <th>hi_500_649_tot</th>\n",
       "      <th>hi_650_799_tot</th>\n",
       "      <th>hi_800_999_tot</th>\n",
       "      <th>hi_1000_1249_tot</th>\n",
       "      <th>hi_1250_1499_tot</th>\n",
       "      <th>hi_1500_1749_tot</th>\n",
       "      <th>hi_1750_1999_tot</th>\n",
       "      <th>hi_2000_2499_tot</th>\n",
       "      <th>hi_2500_2999_tot</th>\n",
       "      <th>hi_3000_3499_tot</th>\n",
       "      <th>hi_3500_3999_tot</th>\n",
       "      <th>hi_4000_more_tot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>2016</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>438</td>\n",
       "      <td>592</td>\n",
       "      <td>446</td>\n",
       "      <td>522</td>\n",
       "      <td>617</td>\n",
       "      <td>765</td>\n",
       "      <td>950</td>\n",
       "      <td>1268</td>\n",
       "      <td>1093</td>\n",
       "      <td>901</td>\n",
       "      <td>768</td>\n",
       "      <td>1352</td>\n",
       "      <td>567</td>\n",
       "      <td>363</td>\n",
       "      <td>541</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>2017</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>420</td>\n",
       "      <td>588</td>\n",
       "      <td>492</td>\n",
       "      <td>563</td>\n",
       "      <td>691</td>\n",
       "      <td>838</td>\n",
       "      <td>1061</td>\n",
       "      <td>1411</td>\n",
       "      <td>1242</td>\n",
       "      <td>1016</td>\n",
       "      <td>875</td>\n",
       "      <td>1584</td>\n",
       "      <td>635</td>\n",
       "      <td>468</td>\n",
       "      <td>514</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>2018</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>402</td>\n",
       "      <td>585</td>\n",
       "      <td>539</td>\n",
       "      <td>605</td>\n",
       "      <td>765</td>\n",
       "      <td>911</td>\n",
       "      <td>1173</td>\n",
       "      <td>1555</td>\n",
       "      <td>1391</td>\n",
       "      <td>1131</td>\n",
       "      <td>982</td>\n",
       "      <td>1817</td>\n",
       "      <td>703</td>\n",
       "      <td>574</td>\n",
       "      <td>488</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>2019</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>385</td>\n",
       "      <td>581</td>\n",
       "      <td>586</td>\n",
       "      <td>647</td>\n",
       "      <td>840</td>\n",
       "      <td>984</td>\n",
       "      <td>1284</td>\n",
       "      <td>1698</td>\n",
       "      <td>1540</td>\n",
       "      <td>1246</td>\n",
       "      <td>1090</td>\n",
       "      <td>2049</td>\n",
       "      <td>771</td>\n",
       "      <td>680</td>\n",
       "      <td>462</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>2020</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>367</td>\n",
       "      <td>578</td>\n",
       "      <td>633</td>\n",
       "      <td>689</td>\n",
       "      <td>914</td>\n",
       "      <td>1057</td>\n",
       "      <td>1396</td>\n",
       "      <td>1842</td>\n",
       "      <td>1689</td>\n",
       "      <td>1361</td>\n",
       "      <td>1197</td>\n",
       "      <td>2282</td>\n",
       "      <td>839</td>\n",
       "      <td>786</td>\n",
       "      <td>436</td>\n",
       "      <td>1277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>2021</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>350</td>\n",
       "      <td>575</td>\n",
       "      <td>680</td>\n",
       "      <td>731</td>\n",
       "      <td>989</td>\n",
       "      <td>1131</td>\n",
       "      <td>1508</td>\n",
       "      <td>1986</td>\n",
       "      <td>1839</td>\n",
       "      <td>1476</td>\n",
       "      <td>1305</td>\n",
       "      <td>2515</td>\n",
       "      <td>907</td>\n",
       "      <td>892</td>\n",
       "      <td>410</td>\n",
       "      <td>1440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year     suburb  hi_1_149_tot  hi_150_299_tot  hi_300_399_tot  \\\n",
       "1710  2016  melbourne           438             592             446   \n",
       "1711  2017  melbourne           420             588             492   \n",
       "1712  2018  melbourne           402             585             539   \n",
       "1713  2019  melbourne           385             581             586   \n",
       "1714  2020  melbourne           367             578             633   \n",
       "1715  2021  melbourne           350             575             680   \n",
       "\n",
       "      hi_400_499_tot  hi_500_649_tot  hi_650_799_tot  hi_800_999_tot  \\\n",
       "1710             522             617             765             950   \n",
       "1711             563             691             838            1061   \n",
       "1712             605             765             911            1173   \n",
       "1713             647             840             984            1284   \n",
       "1714             689             914            1057            1396   \n",
       "1715             731             989            1131            1508   \n",
       "\n",
       "      hi_1000_1249_tot  hi_1250_1499_tot  hi_1500_1749_tot  hi_1750_1999_tot  \\\n",
       "1710              1268              1093               901               768   \n",
       "1711              1411              1242              1016               875   \n",
       "1712              1555              1391              1131               982   \n",
       "1713              1698              1540              1246              1090   \n",
       "1714              1842              1689              1361              1197   \n",
       "1715              1986              1839              1476              1305   \n",
       "\n",
       "      hi_2000_2499_tot  hi_2500_2999_tot  hi_3000_3499_tot  hi_3500_3999_tot  \\\n",
       "1710              1352               567               363               541   \n",
       "1711              1584               635               468               514   \n",
       "1712              1817               703               574               488   \n",
       "1713              2049               771               680               462   \n",
       "1714              2282               839               786               436   \n",
       "1715              2515               907               892               410   \n",
       "\n",
       "      hi_4000_more_tot  \n",
       "1710               626  \n",
       "1711               788  \n",
       "1712               951  \n",
       "1713              1114  \n",
       "1714              1277  \n",
       "1715              1440  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interpolated[df_interpolated['suburb'] == 'melbourne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that for suburbs that did not exist in 2016, their 2017-2020 values == 2021 value\n",
    "# For an example, try uncommenting the line below\n",
    "# df_interpolated[df_interpolated['suburb'] == 'armstrong creek']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING NEW ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "df = df_interpolated.copy()\n",
    "\n",
    "# List of columns to forecast\n",
    "columns_to_forecast = df.columns[2:]  # Assuming the first two columns are 'year' and 'suburb'\n",
    "\n",
    "# Forecast years\n",
    "forecast_years = [2022, 2023, 2024, 2025, 2026, 2027]\n",
    "\n",
    "# Create an empty list to store forecasted results\n",
    "forecast_results = []\n",
    "\n",
    "# Iterate over each suburb\n",
    "for suburb in df['suburb'].unique():\n",
    "    # Filter data for the specific suburb\n",
    "    suburb_data = df[df['suburb'] == suburb].set_index('year')\n",
    "    \n",
    "    # Dictionary to store the forecasted values for each column\n",
    "    suburb_forecast = {'suburb': suburb, 'year': forecast_years}\n",
    "    \n",
    "    for column in columns_to_forecast:\n",
    "        # Extract the time series data for the current column\n",
    "        ts = suburb_data[column]\n",
    "        \n",
    "        # Fit the ARIMA model (p, d, q can be optimized or set manually)\n",
    "        model = ARIMA(ts, order=(1,1,1))\n",
    "        fitted_model = model.fit()\n",
    "        \n",
    "        # Forecast the next 6 years\n",
    "        forecast = fitted_model.forecast(steps=len(forecast_years))\n",
    "        \n",
    "        # Add the forecasted values to the suburb_forecast dictionary\n",
    "        suburb_forecast[column] = forecast.values\n",
    "    \n",
    "    # Append the forecast to the result list\n",
    "    forecast_results.append(pd.DataFrame(suburb_forecast))\n",
    "\n",
    "# Concatenate all forecast results into a single DataFrame\n",
    "forecast_df = pd.concat(forecast_results).reset_index(drop=True)\n",
    "\n",
    "# Display the forecasted DataFrame\n",
    "forecast_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate df_interpolated and forecast_df along the row axis (axis=0)\n",
    "df_combined = pd.concat([df_interpolated, forecast_df], axis=0)\n",
    "\n",
    "# Sort by suburb and year to maintain chronological order\n",
    "df_combined = df_combined.sort_values(by=['suburb', 'year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, select only the numeric columns\n",
    "numeric_columns = df_combined.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Replace negative values with zero only in the numeric columns\n",
    "df_combined[numeric_columns] = df_combined[numeric_columns].applymap(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "# Replace negative values with zero and round the numbers to integers in the numeric columns\n",
    "df_combined[numeric_columns] = df_combined[numeric_columns].applymap(lambda x: round(max(0, x)))\n",
    "\n",
    "# Check the DataFrame to ensure negative values are handled\n",
    "df_combined.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('../data/curated/income_forecasted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
